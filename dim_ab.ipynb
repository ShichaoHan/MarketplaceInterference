{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 14:34:52.816734: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 14:34:53.642237: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.special import kl_div\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "import subprocess\n",
    "import random\n",
    "import time \n",
    "\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.10'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Helper functions and set-ups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graphing set-up \n",
    "import seaborn as sns\n",
    "x = np.linspace(-4, 4, 100)\n",
    "tencent_blue = (0,0.3215686274509804,0.8509803921568627)\n",
    "tencent_orange = (0.9333333333333333, 0.49411764705882355, 0.2784313725490196)\n",
    "\n",
    "# Calculate y-values for the standard normal density curve\n",
    "y_standard_normal = (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Simultation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modifying the tensor for 3d input \n",
    "class MyModel_multiple(Model):\n",
    "    def __init__(self, k, num_treats):\n",
    "        super(MyModel_multiple, self).__init__()\n",
    "        self.k = k\n",
    "        self.num_treats = num_treats\n",
    "        self.groupNames = ['A'] + ['B' + str(i+1) for i in range(self.num_treats)]\n",
    "        self.baseline_logit = Dense(1, activation = \"linear\")\n",
    "        self.outcome = Dense(1, activation = \"linear\")\n",
    "        self.logit_dense_layer = {} \n",
    "        for g in self.groupNames:\n",
    "            self.logit_dense_layer[g] = Dense(1, activation = \"linear\")\n",
    "        self.softmax = tf.keras.activations.softmax\n",
    "        \n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        split_structure =  [2] + [1] * self.num_treats + [1]\n",
    "        splitted_elements = tf.split(inputs, split_structure, axis=2)\n",
    "        x1 = splitted_elements[0]\n",
    "        exposure = tf.squeeze(splitted_elements[self.num_treats + 1], axis=-1)\n",
    "        _, K, dim_x = x1.shape\n",
    "        \n",
    "        \n",
    "        ## Step 1: Reshape the input \n",
    "        reshape_x1 = tf.reshape(x1, (-1, dim_x))\n",
    "        \n",
    "        ## Step 2: Score \n",
    "        ### Baseline logit\n",
    "        x1_final = self.baseline_logit(x1)\n",
    "        \n",
    "        ### Uplift\n",
    "        for i in range(self.num_treats):\n",
    "            w_g = splitted_elements[i + 1]\n",
    "            xg_hidden = self.logit_dense_layer['B'+str(i+1)](x1)\n",
    "            x1_final = tf.add(tf.multiply(w_g, xg_hidden), x1_final)\n",
    "            \n",
    "        ## Step 3: Softmax\n",
    "        logit = tf.reshape(x1_final, (-1, self.k))\n",
    "        softmax_p =  self.softmax(logit, axis=-1)\n",
    "\n",
    "        ## Outcome \n",
    "        ypredicts = self.outcome(x1)\n",
    "        ypredicts = tf.squeeze(ypredicts, axis=-1)\n",
    "\n",
    "        y2 = tf.reduce_sum(tf.multiply(exposure, ypredicts), axis = 1, keepdims=True)\n",
    "        res = tf.concat([softmax_p, logit, y2, ypredicts], axis=1)\n",
    "        return res\n",
    "\n",
    "# Define custom loss function\n",
    "def custom_loss(y_true, y_pred):\n",
    "    y1_true, y2_true = tf.split(y_true, [K, 1], axis=1)\n",
    "    _, y1_logit_pred, y2_pred, _= tf.split(y_pred, [K, K, 1, K], axis=1)\n",
    "    loss1 = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(y1_true, y1_logit_pred)\n",
    "    loss2 = tf.keras.losses.MeanSquaredError()(y2_true, y2_pred)\n",
    "    return loss1 + loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modifying the tensor for 3d input \n",
    "class MyModel_true():\n",
    "    def __init__(self, k, promo):\n",
    "        self.k = k\n",
    "        self.promo = promo\n",
    "        \n",
    "    \n",
    "    def predict(self, inputs):\n",
    "\n",
    "        X_goodbads, X_utility, W_matrix, exposure_matrix = np.split(inputs, [1,2,3], axis=2)\n",
    "        logit = self.promo * W_matrix * X_goodbads + X_utility\n",
    "        logit = np.squeeze(logit, axis=-1)\n",
    "        softmax_p =  np.exp(logit) / np.sum(np.exp(logit), axis=1, keepdims=True)\n",
    "\n",
    "        ypredicts = np.squeeze(X_utility, axis=-1)\n",
    "\n",
    "        exposure = np.squeeze(exposure_matrix, axis=-1)\n",
    "\n",
    "        y2 = np.sum(exposure * ypredicts, axis = 1, keepdims=True)\n",
    "        res = np.concatenate([softmax_p, logit, y2, ypredicts], axis=1)\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel_random():\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "\n",
    "        X_goodbads, X_utility, W_matrix, exposure_matrix = np.split(inputs, [1,2,3], axis=2)\n",
    "        K = X_utility.shape[1]\n",
    "        logit = np.ones_like(X_utility)\n",
    "        logit = np.squeeze(logit, axis=-1)\n",
    "        softmax_p = np.ones_like(logit) / K\n",
    "        ypredicts = np.squeeze(X_utility, axis=-1)\n",
    "\n",
    "        exposure = np.squeeze(exposure_matrix, axis=-1)\n",
    "\n",
    "        y2 = np.sum(exposure * ypredicts, axis = 1, keepdims=True)\n",
    "        res = np.concatenate([softmax_p, logit, y2, ypredicts], axis=1)\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 30 \n",
    "K = 5 \n",
    "Q = 800 \n",
    "uplift_factor = 1.0\n",
    "truth_estimate, truth_stderr = find_ate_ground_truth(J, K, Q, uplift_factor)\n",
    "\n",
    "L = 1\n",
    "\n",
    "M = 500 ## Number of iterations for Hessian matrix estimation \n",
    "n_folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start K = 5, Q = 800, J = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 14:35:54.127498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 37132 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 14:35:54.129761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 37798 MB memory:  -> device: 1, name: A100-SXM4-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "2024-06-11 14:35:54.131625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 28265 MB memory:  -> device: 2, name: A100-SXM4-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n",
      "2024-06-11 14:35:54.133326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 28279 MB memory:  -> device: 3, name: A100-SXM4-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 2s 4ms/step - loss: 6.1800\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5.8274\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5.5035\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5.1956\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.9354\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.6900\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.4777\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.2779\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.1042\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.9527\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 80.1444\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 78.1997\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 76.1628\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 74.2696\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 72.3918\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 70.5546\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 68.7761\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 66.9497\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 65.3138\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 63.5680\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 60.9280\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 59.1908\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 57.4756\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 55.8270\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 54.1256\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 52.5469\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 51.0068\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 49.4305\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 47.9285\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 46.4809\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "finish simulation.\n"
     ]
    }
   ],
   "source": [
    "B = 1\n",
    "epochs = 400\n",
    "np.random.seed(int(time.time() * 1e8 % 1e8))\n",
    "print(\"Start K = {}, Q = {}, J = {}\".format(str(K), str(Q), str(J)))\n",
    "for b in range(B):\n",
    "    (X_utility, X_goodbads, query_matrix, utility_score_matrix, \n",
    "     treatment_dict, utility_score, good_bad_dict) = generate_environment(J, K, Q, uplift_factor)\n",
    "    (query_matrix, X_goodbads, X_utility,W_matrix, exposure_matrix, \n",
    "     outcome_potential, X_logit) = DGP_new_heterogeneous(J, Q, K, uplift_factor, query_matrix, X_goodbads, \n",
    "                                                         X_utility, treat_control_pool = [True, False])\n",
    "    observed_queries_treatment = np.sum(exposure_matrix * W_matrix, axis = 1 )\n",
    "    observed_outcome = np.sum(outcome_potential * exposure_matrix, axis = 1 )\n",
    "    T, C = observed_outcome[observed_queries_treatment == 1] , observed_outcome[observed_queries_treatment == 0]  \n",
    "        \n",
    "    \n",
    "    ## Cross-fitting indices \n",
    "    all_inds = generate_indices(np.array(query_matrix).shape[0], n_folds)\n",
    "\n",
    "    ## Iterate over each fold for cross-validation. \n",
    "    hfuncs_each_fold,  debias_terms_each_fold = {}, {}\n",
    "\n",
    "    for f in range(n_folds):\n",
    "        f_start, f_end = all_inds[f]\n",
    "        f_size = f_end - f_start\n",
    "        \n",
    "        ## Cross-fitting\n",
    "        X_goodbads_train, X_goodbads_test =  train_test_split(X_goodbads, all_inds, f) \n",
    "        X_utility_train, X_utility_test =  train_test_split(X_utility, all_inds, f)  \n",
    "        W_matrix_train, W_matrix_test = train_test_split(W_matrix, all_inds, f) \n",
    "        exposure_matrix_train, exposure_matrix_test =train_test_split(exposure_matrix, all_inds, f) \n",
    "        observed_outcome_train, observed_outcome_test = train_test_split(observed_outcome, all_inds, f) \n",
    "        \n",
    "        outcome_potential_train, outcome_potential_test = train_test_split(outcome_potential, all_inds, f)  \n",
    "    \n",
    "        inputs_3d_train = np.stack([X_goodbads_train, X_utility_train, W_matrix_train, exposure_matrix_train], axis = -1)\n",
    "        inputs_3d_test = np.stack([X_goodbads_test, X_utility_test, W_matrix_test, exposure_matrix_test], axis = -1)\n",
    "        output_3d_train = np.concatenate([exposure_matrix_train.astype(dtype=float), observed_outcome_train[:, np.newaxis]], axis = 1)\n",
    "\n",
    "        myModelMultiple = MyModel_multiple(K, 1)\n",
    "        myModelMultiple.compile(loss=custom_loss, optimizer=tf.keras.optimizers.legacy.Adam())\n",
    "        myModelMultiple.fit(inputs_3d_train, output_3d_train, epochs=epochs, verbose=True)\n",
    "        # myModelMultiple = MyModel_true(K, uplift_factor)\n",
    "        # myModelMultiple = MyModel_random()\n",
    "\n",
    "        predict_p_test, _, _, predict_outcome_test = np.split(myModelMultiple.predict(inputs_3d_test), [K, 2*K, 2*K+1], axis=1)\n",
    "\n",
    "        input_3d_test_treat = np.stack([X_goodbads_test, X_utility_test, np.ones_like(W_matrix_test), exposure_matrix_test], axis = -1)\n",
    "        input_3d_test_control = np.stack([X_goodbads_test, X_utility_test, np.zeros_like(W_matrix_test), exposure_matrix_test], axis = -1)\n",
    "        \n",
    "        predict_p_treat, _, _, predict_outcome_treat = np.split(myModelMultiple.predict(input_3d_test_treat), [K, 2*K, 2*K+1], axis=1)\n",
    "        predict_p_control, _, _, predict_outcome_control = np.split(myModelMultiple.predict(input_3d_test_control), [K, 2*K, 2*K+1], axis=1)\n",
    "        \n",
    "\n",
    "        ## 1. COMPUTE THE GRADIENT OF LOSSS  \n",
    "        gradient_vector_l = compute_loss_gradient(predict_p_test, exposure_matrix_test, W_matrix_test, \n",
    "                                                  predict_outcome_test, observed_outcome_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ## 2. COMPUTE  THE GRADIENT OF H FUNCTION\n",
    "        gradient_vector_H = compute_value_gradient(predict_p_treat, predict_outcome_treat, predict_p_control, predict_outcome_control)\n",
    "\n",
    "        \n",
    "        # 3. FIND THE EXPECTATION OF HESSIAN MATRIX \n",
    "        Hessian_all = np.zeros((f_size, (L+2) * K - 1,  (L+2) * K - 1))\n",
    "        for m in range(M):\n",
    "            treat_dict_m = permute_treatment_dict(J, L)\n",
    "            W_matrix_m = []\n",
    "            for each_query in query_matrix[f_start:f_end]:\n",
    "                W_matrix_m.append([treat_dict_m[ind] for ind in each_query])\n",
    "            W_matrix_m = np.array(W_matrix_m)\n",
    "            inputs_m = tf.stack([X_goodbads_test, X_utility_test, W_matrix_m, exposure_matrix_test], axis = -1)\n",
    "            predict_p_m, _, _, _ = np.split(myModelMultiple.predict(inputs_m), [K, 2*K, 2*K+1], axis=1)\n",
    "            Hessian = compute_hessian_instance(W_matrix_m, predict_p_m)\n",
    "            Hessian_all = Hessian_all + Hessian\n",
    "        Hessian_final = Hessian_all / M\n",
    "        \n",
    "        count_finite = 0\n",
    "        debias_term_f = np.zeros(len(Hessian_final))\n",
    "        for i in range(f_size):\n",
    "            if is_invertible(Hessian_final[i]):\n",
    "                try:\n",
    "                    debias_term_f[i] = gradient_vector_H[i]@np.linalg.inv(Hessian_final[i])@gradient_vector_l[i]\n",
    "                    count_finite += 1 \n",
    "                except: \n",
    "                    print(\"Fail for inversion\")\n",
    "\n",
    "\n",
    "        ## END OF FOR LOOP FOR EACH ITERATION OVER CROSS FITTING\n",
    "        hfuncs_each_fold[f] = np.sum(predict_p_treat * predict_outcome_treat, axis=1) - np.sum(predict_p_control * predict_outcome_control, axis=1)\n",
    "        debias_terms_each_fold[f] = debias_term_f\n",
    "        \n",
    "    (debias_point, debias_var, undebias_point, undebias_var) = crossfitted_estimate_var(hfuncs_each_fold, debias_terms_each_fold)\n",
    "    dim_point, dim_var = dim_est(T, C, 0.5, Q)\n",
    "\n",
    "    path = compose_filename(f\"results1106/new_heterogeneous_synthetic_ab_j{J}q{Q}k{K}_100_{uplift_factor}\", \"csv\")\n",
    "    result_df = pd.DataFrame({\"debias_point\": [debias_point], \"debias_var\":[debias_var], \"dim\": [dim_point], \n",
    "                              \"dim_var\":[dim_var], \"undebias_point\": [undebias_point], \"undebias_var\": [undebias_var], \n",
    "                              \"J\" : [J], \"Q\": [Q],  \"K\":[K], \"truth\": [truth_estimate], \"truth_stderr\": [truth_stderr] })\n",
    "    result_df.to_csv(path)\n",
    "    print(\"finish simulation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debias_point</th>\n",
       "      <th>debias_var</th>\n",
       "      <th>dim</th>\n",
       "      <th>dim_var</th>\n",
       "      <th>undebias_point</th>\n",
       "      <th>undebias_var</th>\n",
       "      <th>J</th>\n",
       "      <th>Q</th>\n",
       "      <th>K</th>\n",
       "      <th>truth</th>\n",
       "      <th>truth_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061009</td>\n",
       "      <td>133.579209</td>\n",
       "      <td>0.813835</td>\n",
       "      <td>116.689613</td>\n",
       "      <td>-0.802028</td>\n",
       "      <td>3.132969</td>\n",
       "      <td>30</td>\n",
       "      <td>800</td>\n",
       "      <td>5</td>\n",
       "      <td>0.017009</td>\n",
       "      <td>0.000638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   debias_point  debias_var       dim     dim_var  undebias_point  \\\n",
       "0      0.061009  133.579209  0.813835  116.689613       -0.802028   \n",
       "\n",
       "   undebias_var   J    Q  K     truth  truth_stderr  \n",
       "0      3.132969  30  800  5  0.017009      0.000638  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
