{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 19:06:01.954649: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-25 19:06:02.118689: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-25 19:06:02.124219: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-04-25 19:06:02.124250: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-25 19:06:02.951415: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-25 19:06:02.951506: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-25 19:06:02.951517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import Model \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import layers\n",
    "from scipy.special import kl_div\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_ranking as tfr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated - April Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "x = np.linspace(-4, 4, 100)\n",
    "tencent_blue = (0,0.3215686274509804,0.8509803921568627)\n",
    "tencent_orange = (0.9333333333333333, 0.49411764705882355, 0.2784313725490196)\n",
    "\n",
    "\n",
    "# Calculate y-values for the standard normal density curve\n",
    "y_standard_normal = (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_probability_exposure_examination(probs_matrix, exposure_matrix): \n",
    "    aggregate_probs = np.mean(probs_matrix, axis = 0)\n",
    "    exposure_probs = np.mean(exposure_matrix, axis = 0)\n",
    "    ## Euclidean distance \n",
    "    euc_dist = np.linalg.norm(aggregate_probs - exposure_probs)\n",
    "    ## NDCG LOSS \n",
    "    y_true = tf.ragged.constant(exposure_matrix)\n",
    "    y_pred = tf.ragged.constant(probs_matrix)\n",
    "    loss_NDCG = tfr.keras.losses.ApproxNDCGLoss(ragged=True)\n",
    "    NDCG_loss_result = loss_NDCG(y_true, y_pred).numpy()\n",
    "    return euc_dist, aggregate_probs, exposure_probs, NDCG_loss_result\n",
    "def mySoftMax(arr):\n",
    "    num = np.exp(arr)\n",
    "    denom = np.sum(num)\n",
    "    return num/denom\n",
    "\n",
    "\n",
    "def naive_est(res):\n",
    "    treat_res = [elm[0] for elm in res[0]]\n",
    "    control_res = [elm[1] for elm in res[0]]\n",
    "    return np.mean(treat_res) - np.mean(control_res)\n",
    "\n",
    "\n",
    "def dim_est(obs_T, obs_C):\n",
    "    n1,n0 = len(obs_T), len(obs_C)\n",
    "    return np.mean(obs_T) -np.mean(obs_C), np.sqrt(np.var(obs_T)/n1 + np.var(obs_C) / n0)\n",
    "\n",
    "\n",
    "def point_est(all_treat_array, all_control_array):\n",
    "    mus_T, mus_C  = all_treat_array[:, 11:21], all_control_array[:,11:21]\n",
    "    p_T, p_C  = all_treat_array[:, 21:], all_control_array[:,21:]\n",
    "    return np.mean(np.sum((mus_T * (p_T - p_C)), axis = 1 ))\n",
    "\n",
    "\n",
    "def naive_dim_estimate(vector_T, vector_C):\n",
    "    return np.mean(vector_T) - np.mean(vector_C), np.var(vector_T)/len(vector_T) + np.var(vector_C) / len(vector_C)\n",
    "\n",
    "def debias_estimator(Hfuncs, debias_terms):\n",
    "    score_functions = Hfuncs - debias_terms \n",
    "    undebiased_estimator = np.mean(Hfuncs)\n",
    "    debiased_estimator = np.mean(score_functions)\n",
    "    variance_estimator = np.mean((score_functions - debiased_estimator)**2) /len(score_functions)\n",
    "    return debiased_estimator, variance_estimator, undebiased_estimator \n",
    "\n",
    "def debias_estimator_new(Hfuncs, debias_terms,tau_hat):\n",
    "    psi_functions = Hfuncs - debias_terms \n",
    "    undebiased_estimator = np.mean(Hfuncs)\n",
    "    debiased_estimator = np.mean(psi_functions)\n",
    "    variance_estimator = np.sum((psi_functions - tau_hat)**2) /len(psi_functions)\n",
    "    return debiased_estimator, variance_estimator, undebiased_estimator \n",
    "\n",
    "\n",
    "def is_invertible(matrix):\n",
    "    return np.linalg.det(matrix) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## True Model \n",
    "\n",
    "class MyModel_True:\n",
    "    def __init__(self, k, num_treats,promo_ratio):\n",
    "\n",
    "        self.k = k\n",
    "        self.promo_ratio = promo_ratio\n",
    "        self.num_treats = num_treats\n",
    "\n",
    "    def predict(self,inputs):\n",
    "        Q_input = inputs.shape[0]\n",
    "        split_structure =  [1]+ [1] + [1] * self.num_treats + [1]\n",
    "        splitted_elements = tf.split(inputs, split_structure, axis=2)\n",
    "        X_utility =  np.squeeze(np.array(splitted_elements[1]), axis=2)\n",
    "        X_goodbads = np.squeeze(np.array(splitted_elements[0]), axis = 2)\n",
    "\n",
    "        W_matrix =  np.squeeze(np.array(splitted_elements[2]), axis =2 )\n",
    "\n",
    "        final_score_matrix = (1 + W_matrix * self.promo_ratio * X_goodbads) * X_utility\n",
    "\n",
    "        ## First element of each row \n",
    "        first_elm = X_utility[:,0]\n",
    "        minus_matrix = first_elm.reshape((len(first_elm),1))@np.ones((1,K))\n",
    "        final_score_matrix_normalized = final_score_matrix - minus_matrix\n",
    "        ## Correct exposure probability \n",
    "        X_logit = np.apply_along_axis(logistic_row, axis=1, arr=final_score_matrix_normalized)\n",
    "    \n",
    "        expose_indices = np.argmax(X_logit, axis = 1)\n",
    "        inddds = np.array(list(np.arange(K)) * Q_input).reshape(Q_input,K)\n",
    "        exposure_matrix = np.array([inddds[i,:] == expose_indices[i] for i in range(Q_input)])\n",
    "\n",
    "        ## Outcome model  \n",
    "        \n",
    "        ## First: a true outcome model of Exponential \n",
    "        outcome_potential = np.random.normal(size=(Q_input, K)) +  X_utility\n",
    "        pred_out = np.sum(exposure_matrix * outcome_potential, axis = 1 )\n",
    "        pred_out = pred_out.reshape(pred_out.shape[0], 1 )\n",
    "        return np.concatenate([X_logit, pred_out], axis = 1 )\n",
    "## True Model \n",
    "\n",
    "class MyModel_Random:\n",
    "    def __init__(self, k, num_treats,promo_ratio):\n",
    "\n",
    "        self.k = k\n",
    "        self.promo_ratio = promo_ratio\n",
    "        self.num_treats = num_treats\n",
    "\n",
    "    def predict(self,inputs):\n",
    "        output_shape = np.array(input_3d_test_treat.shape)[:2]\n",
    "        array = np.random.rand(output_shape[0],output_shape[1])\n",
    "        # Compute the sum of each row\n",
    "        row_sums = np.sum(array, axis=1)\n",
    "\n",
    "        # Reshape the row sums to make them compatible for broadcasting\n",
    "        row_sums = row_sums.reshape(-1, 1)\n",
    "\n",
    "        normalized_array = array / row_sums\n",
    "\n",
    "        return normalized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of videos \n",
    "J = 50 \n",
    "## Consideration set size \n",
    "K = 10 \n",
    "k=10\n",
    "## Generate some queries along with the recommendation model \n",
    "Q = 1000\n",
    "\n",
    "\n",
    "def permute_treatment_dict(J):\n",
    "    perm_dict = {}\n",
    "    for j in range(J):\n",
    "        perm_dict[j] = np.random.choice([True,False], 1)\n",
    "    return perm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## True Exposure Model and Data Generating Process \n",
    "def logistic_row(row):\n",
    "    return np.exp(row) / np.sum(np.exp(row))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# I. deterministic: \n",
    "# selected_indices = np.argmax(X_logit, axis = 1)\n",
    "# II. random choice for exposure \n",
    "\n",
    "def DGP(promo_rat, K,Q, J):\n",
    "    ## Generate a utility score for each viewer and video pair\n",
    "    utility_score_matrix = np.exp(np.random.normal(size=(Q,J)))\n",
    "    good_bad_dict = {} \n",
    "    treatment_dict = {} \n",
    "    utility_score = {} \n",
    "    for j in range(J):\n",
    "        good_bad_dict[j] = np.random.choice([True,False], 1)\n",
    "        treatment_dict[j] = np.random.choice([True,False], 1)\n",
    "        utility_score[j] = np.random.uniform()\n",
    "    X_goodbads = []\n",
    "    X_utility = []\n",
    "    W_matrix = []\n",
    "    query_matrix = []\n",
    "    promo_ratio = promo_rat\n",
    "    for each_query in range(Q):\n",
    "        ## Form the consideration set \n",
    "        selected_indices = np.random.choice(np.arange(J), K, replace= False)\n",
    "        query_matrix += [selected_indices]\n",
    "        X_goodbads = np.append(X_goodbads,[good_bad_dict[ind] for ind in selected_indices])\n",
    "        X_utility = np.append(X_utility, [utility_score_matrix[each_query, ind] for ind in selected_indices])\n",
    "        W_matrix = np.append(W_matrix, [treatment_dict[ind] for ind in selected_indices])\n",
    "    X_goodbads = X_goodbads.reshape(Q, K)\n",
    "    X_utility = X_utility.reshape(Q, K)\n",
    "    W_matrix = W_matrix.reshape(Q,K)\n",
    "    final_score_matrix = (1 + W_matrix * promo_ratio * X_goodbads) * X_utility\n",
    "\n",
    "    X_logit = np.apply_along_axis(logistic_row, axis=1, arr=final_score_matrix)\n",
    "    expose_indices = np.array([np.random.choice(np.arange(K), size = 1, p = X_logit[i,:]) for i in range(Q)])\n",
    "    inddds = np.array(list(np.arange(K)) * Q).reshape(Q,K)\n",
    "    exposure_matrix = np.array([inddds[i,:] == expose_indices[i] for i in range(Q)])\n",
    "\n",
    "    ## Outcome model  \n",
    "    ## First: a true outcome model of Exponential \n",
    "    outcome_potential = np.random.normal(size=(Q, K)) +  X_utility\n",
    "\n",
    "    return query_matrix,X_goodbads,X_utility,W_matrix, exposure_matrix, outcome_potential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_B, dim_var_B= [],[]\n",
    "debias_B_true, debias_var_B_true = [],[] \n",
    "undebias_B_true, debias_var_old_B_true = [],[]\n",
    "truth= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function for cross validation\n",
    "def generate_indices(n, K):\n",
    "    ## Split original sample of size n into K sets \n",
    "    indices = np.linspace(0, n, K+1, dtype=int)\n",
    "    return list(zip(indices[:-1], indices[1:]))\n",
    "\n",
    "\n",
    "def train_test_split(input_data, all_inds, kth_test):\n",
    "    \n",
    "    training_ind = [all_inds[i] for i in range(len(all_inds)) if i != kth_test]\n",
    "    test_start, test_end = all_inds[kth_test]\n",
    "    if not tf.is_tensor(input_data):\n",
    "        training_data = np.concatenate([input_data[elm[0]:elm[1]] for elm in training_ind])\n",
    "    else:\n",
    "        \n",
    "        training_data = tf.concat([input_data[elm[0]:elm[1]] for elm in training_ind], axis = 0)\n",
    "    testing_data = input_data[test_start:test_end]\n",
    "    return training_data, testing_data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start K = 5, Q = 1000, J = 50\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 19:09:28.081732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-04-25 19:09:28.081794: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-04-25 19:09:28.081820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (VM-210-136-centos): /proc/driver/nvidia/version does not exist\n",
      "2024-04-25 19:09:28.082286: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "## Number of iterations of DGP\n",
    "B = 100\n",
    "## Number of videos \n",
    "JQ_sizes = [(50,1000), (100,1000), (200, 1000)]\n",
    "training_ratio = 0.4\n",
    "\n",
    "num_features = 2 \n",
    "\n",
    "## Consideration set size \n",
    "Ks = [5,10,20]\n",
    "\n",
    "JQ_sizes = [(50,1000)]\n",
    "Ks = [5]\n",
    "\n",
    "\n",
    "for (J, Q) in JQ_sizes:\n",
    "    for K in Ks:\n",
    "        print(\"Start K = {}, Q = {}, J = {}\".format(str(K), str(Q), str(J)))\n",
    "        dim_B, dim_var_B= [],[]\n",
    "        debias_B_true, debias_var_B_true = [],[] \n",
    "        undebias_B_true, debias_var_old_B_true = [],[]\n",
    "        truth= []\n",
    "\n",
    "\n",
    "        ## True Outcome Model test \n",
    "        L = 1\n",
    "        ith_treat = 0\n",
    "        M = 100\n",
    "        groupNames = [0,1]\n",
    "        uplift_ratio = 0\n",
    "        k = K\n",
    "        n_folds = 3\n",
    "        for b in range(B):\n",
    "            if b % 20 == 0:\n",
    "                print(b)\n",
    "            ## DGP and data pre-processing \n",
    "            query_matrix,X_goodbads,X_utility,W_matrix, exposure_matrix, outcome_potential = DGP(uplift_ratio, K,Q,J)\n",
    "\n",
    "            ## Fix in v2: add cross-fitting to the code \n",
    "            all_inds = generate_indices(np.array(query_matrix).shape[0], n_folds)\n",
    "            \n",
    "\n",
    "            ## Iterate over each fold for cross-validation. \n",
    "\n",
    "            hfuncs_each_fold,  debias_terms_each_fold = {},{}\n",
    "            for f in range(n_folds):\n",
    "                f_start, f_end = all_inds[f]\n",
    "                query_train, query_test = train_test_split(np.array(query_matrix), all_inds, f)\n",
    "                X_goodbads_train, X_goodbads_test =  train_test_split(X_goodbads, all_inds, f) \n",
    "                X_utility_train, X_utility_test =  train_test_split(X_utility, all_inds, f)  \n",
    "                W_matrix_train, W_matrix_test = train_test_split(W_matrix, all_inds, f) \n",
    "                observed_queries_treatment = np.sum(exposure_matrix * W_matrix, axis = 1 )\n",
    "                observed_outcome = np.sum(outcome_potential * exposure_matrix, axis = 1 )\n",
    "\n",
    "                T, C = observed_outcome[observed_queries_treatment == groupNames[ith_treat + 1 ]] , observed_outcome[observed_queries_treatment == 0]  \n",
    "                exposure_matrix_train,exposure_matrix_test =train_test_split(exposure_matrix, all_inds, f) \n",
    "                outcome_matrix = exposure_matrix * outcome_potential\n",
    "                outcome_matrix = np.sum(outcome_matrix, axis = 1 ).reshape(outcome_matrix.shape[0],1)\n",
    "\n",
    "                observed_outcome_train, observed_outcome_test = train_test_split(observed_outcome, all_inds, f) \n",
    "                outcome_matrix_train, outcome_matrix_test = train_test_split(outcome_matrix, all_inds, f) \n",
    "                outcome_potential_train, outcome_potential_test = train_test_split(outcome_potential, all_inds, f)  \n",
    "                inputs_3d_train = tf.stack([X_goodbads_train,X_utility_train, W_matrix_train, X_utility_train ], axis = -1)\n",
    "                inputs_3d_test = tf.stack([X_goodbads_test,X_utility_test, W_matrix_test, X_utility_test], axis = -1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                input_3d_test_treat = tf.stack([X_goodbads_test,X_utility_test, np.ones(W_matrix_test.shape), X_utility_test], axis = -1)\n",
    "                input_3d_test_control = tf.stack([X_goodbads_test,X_utility_test, np.zeros(W_matrix_test.shape), X_utility_test], axis = -1)\n",
    "                output_3d_train = tf.concat([tf.cast(exposure_matrix_train, dtype=float),outcome_matrix_train], axis = 1)\n",
    "                output_3d_test = tf.concat([tf.cast(exposure_matrix_test, dtype=float),outcome_matrix_test ], axis = 1)\n",
    "\n",
    "                exposure_indicator_array = exposure_matrix_test\n",
    "\n",
    "\n",
    "                ## Get treatment indicator matrix\n",
    "                w_dict = {}\n",
    "\n",
    "                for l in range(L):\n",
    "                    w_dict[l] = tf.convert_to_tensor(W_matrix == groupNames[l+1], dtype = float)\n",
    "\n",
    "                training_num = int(W_matrix.shape[0] * training_ratio)\n",
    "                testing_num = W_matrix.shape[0] - training_num\n",
    "\n",
    "\n",
    "                w_all_treat = tf.convert_to_tensor(np.array([[1] * k for _ in range(W_matrix.shape[0])],dtype='float32'))\n",
    "                w_all_control = tf.convert_to_tensor(np.array([[0] * k for _ in range(W_matrix.shape[0])],dtype='float32'))\n",
    "\n",
    "                inputs_all_treat_3d = tf.stack([X_goodbads,X_utility] + [w_all_treat if l == ith_treat else w_all_control for l in range(L)] +[ X_utility], axis = 2)\n",
    "                inputs_all_control_3d = tf.stack([X_goodbads,X_utility] + [w_all_control if l == ith_treat else w_all_control for l in range(L)] +[ X_utility ], axis = 2)\n",
    "                inputs_all_treat_3d = tf.cast(inputs_all_treat_3d, dtype = 'float32')\n",
    "                inputs_all_control_3d = tf.cast(inputs_all_control_3d, dtype = 'float32')\n",
    "\n",
    "                ## All other all_treated \n",
    "                inputs_all_treat_3d_dict = {} \n",
    "                for l in range(L):\n",
    "                    inputs_all_treat_3d_l = tf.stack([X_goodbads,X_utility] + [w_all_treat if l == v else w_all_control for v in range(L)] +[ X_utility ], axis = 2)\n",
    "                    #inputs_all_treat_3d_l = tf.stack([x_basebid, x_sort_score, x_bid,x_ecpm, x_cvr] + [w_all_treat if v == l else w_all_control for v in range(L)] + [x_cvr], axis = 2)\n",
    "                    inputs_all_treat_3d_dict[l] = tf.cast(inputs_all_treat_3d_l, dtype = 'float32')\n",
    "\n",
    "                exposure_indicator_outcome_train, exposure_indicator_outcome_test = outcome_matrix_train, outcome_matrix_test\n",
    "                inputs_all_treat_3d_test = input_3d_test_treat\n",
    "                inputs_all_control_3d_test = input_3d_test_control\n",
    "                is_selected_indicator_train,is_selected_indicator_test = exposure_matrix_train,exposure_matrix_test\n",
    "\n",
    "                treat_control_dict = {} \n",
    "                for l in range(L):\n",
    "\n",
    "                    \n",
    "                    inputs_3d_train_l,inputs_3d_test_l= train_test_split(inputs_all_treat_3d_dict[l], all_inds, f) \n",
    "\n",
    "                    treat_control_dict[l] = {'train':inputs_3d_train_l, 'test': inputs_3d_test_l}\n",
    "\n",
    "                myModelMultiple = MyModel_True(K, L, uplift_ratio)\n",
    "                myModelMultiple_random = MyModel_Random(K, L, uplift_ratio)\n",
    "                # myModelMultiple.compile(loss=custom_loss,optimizer=tf.keras.optimizers.legacy.Adam())\n",
    "                # myModelMultiple.fit(input_3d_train,output_3d_train , epochs=10, verbose=False)\n",
    "                exposure_indicator_array = is_selected_indicator_test\n",
    "                treatment_indicator_array = 1 * (np.array(w_dict[ith_treat])[f_start:f_end,:])\n",
    "\n",
    "                res_tempt = np.array(myModelMultiple.predict(inputs_all_treat_3d_test)) - np.array(myModelMultiple.predict(inputs_all_control_3d_test))\n",
    "\n",
    "\n",
    "                pred_H_new = np.array(myModelMultiple.predict(inputs_all_treat_3d_test)) - np.array(myModelMultiple.predict(inputs_all_control_3d_test))\n",
    "                model_pred_H = np.array(myModelMultiple.predict(inputs_3d_test))\n",
    "                model_pred_all_treat = myModelMultiple.predict(inputs_all_treat_3d_test)\n",
    "                model_pred_all_control = myModelMultiple.predict(inputs_all_control_3d_test)\n",
    "                all_treat_array, all_control_array = np.array(model_pred_all_treat), np.array(model_pred_all_control)\n",
    "\n",
    "                ## All other counterfactuals \n",
    "                counterfactual_pred_dict = {} \n",
    "                for l in range(L):\n",
    "                    model_pred_all_l = myModelMultiple.predict(treat_control_dict[l]['test'])\n",
    "                    counterfactual_pred_dict[l] = model_pred_all_l\n",
    "\n",
    "                ## Outcome - prediction model \n",
    "                indicator_bool = tf.cast(is_selected_indicator_train, dtype=tf.bool)\n",
    "                selected_elements = tf.boolean_mask(inputs_3d_train[:,:,:num_features], indicator_bool)\n",
    "\n",
    "                input_to_outcomemodel_train = tf.reshape(selected_elements, (inputs_3d_train.shape[0], num_features))\n",
    "                # Define your base model\n",
    "                base_model = tf.keras.Sequential()\n",
    "                base_model.add(layers.Dense(1, input_shape=(num_features,)))\n",
    "\n",
    "                # Compile the model\n",
    "                base_model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "                base_model.fit(input_to_outcomemodel_train,output_3d_train[:, K],epochs=50, verbose=False)\n",
    "                # Now define a new model for prediction\n",
    "                model_for_prediction = tf.keras.Sequential()\n",
    "                model_for_prediction.add(layers.TimeDistributed(base_model, input_shape=(K, num_features)))\n",
    "                predictions = model_for_prediction.predict(inputs_3d_test[:,:,:num_features])\n",
    "                # Remove the third dimension of size 1\n",
    "                numpy_array_pred = np.squeeze(predictions, axis=2)\n",
    "\n",
    "                mus_T, mus_C  = numpy_array_pred,numpy_array_pred\n",
    "                p_T, p_C  = all_treat_array[:, :k], all_control_array[:,:k]\n",
    "                rewards_array = observed_outcome_test\n",
    "                rewards_array = rewards_array.reshape(rewards_array.shape[0],1)\n",
    "                Ey1,Ey0 = np.sum(mus_T * p_T, axis = 1), np.sum(mus_C * p_C, axis = 1)\n",
    "                pv1,pv0 = np.sum(exposure_indicator_array * p_T, axis = 1), np.sum(exposure_indicator_array * p_C, axis = 1)\n",
    "\n",
    "                pv_given_uvw = p_T * treatment_indicator_array + p_C * (1 - treatment_indicator_array)\n",
    "\n",
    "\n",
    "                p_realized = model_pred_H[:,:K]\n",
    "\n",
    "\n",
    "\n",
    "                ## 1. COMPUTE THE GRADIENT OF LOSSS  \n",
    "                ## FIX: change to realized outcome \n",
    "                #dl1dtheta0 = pv_given_uvw - exposure_indicator_array\n",
    "                dl1dtheta0 = p_realized - exposure_indicator_array\n",
    "                dl1dtheta0 = dl1dtheta0[:, 1:] \n",
    "\n",
    "\n",
    "                ## FIX: iterate over all L \n",
    "                dl1dthetal_dict = {} \n",
    "                for l in range(L):\n",
    "                    treatment_indicator_array_l = w_dict[l][f_start:f_end, :]\n",
    "                    dl1dthetal_dict[l] = treatment_indicator_array_l *  (p_realized - exposure_indicator_array)\n",
    "                dl2dmu = exposure_indicator_array * (mus_T -rewards_array)\n",
    "                gradient_vector_l = np.concatenate([dl1dtheta0]+[dl1dthetal_dict[l] for l in range(L)] +[dl2dmu], axis =1 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ## 2. COMPUTE  THE GRADIENT OF H FUNCTION\n",
    "                dHdtheta0 = p_T * (mus_T - Ey1.reshape(mus_T.shape[0],1)) - p_C * (mus_C - Ey0.reshape(mus_C.shape[0],1))\n",
    "                dHdtheta0 = dHdtheta0[:, 1:]\n",
    "\n",
    "\n",
    "\n",
    "                ## FIX: iterate over each l \n",
    "                dHdthetal_dict = {} \n",
    "                for l in range(L):\n",
    "\n",
    "                    p_T_thetal = counterfactual_pred_dict[l][:,:k]\n",
    "                    Eyl = np.sum(mus_T * p_T_thetal, axis = 1)\n",
    "                    dHdthetal_dict[l] = p_T_thetal * (mus_T - Eyl.reshape(mus_T.shape[0],1))\n",
    "                    ## 0 for the groups that are not the target treatment group \n",
    "                    if l != ith_treat:\n",
    "                        dHdthetal_dict[l] = 0 * (p_T_thetal * (mus_T - Eyl.reshape(mus_T.shape[0],1)))\n",
    "\n",
    "                #dHdthetal = p_T * (mus_T - Ey1.reshape(mus_T.shape[0],1))\n",
    "                dHdmu = p_T - p_C\n",
    "                #gradient_vector_H = np.concatenate([dHdtheta0,dHdthetal,dHdmu], axis =1 )\n",
    "\n",
    "                ## FIX: iterate over all l \n",
    "                gradient_vector_H = np.concatenate([dHdtheta0]+[dHdthetal_dict[l] for l in range(L)]+[dHdmu], axis =1 )\n",
    "                ## Gradient over all other treatments \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ## 3. FIND THE EXPECTATION OF HESSIAN MATRIX \n",
    "\n",
    "\n",
    "\n",
    "                Hessian_all = np.zeros((inputs_3d_test.shape[0],(L+2) * K - 1,  (L+2) * K - 1))\n",
    "\n",
    "                montecarlo_expected_probability = np.zeros(exposure_indicator_array.shape)\n",
    "\n",
    "                selected_indicator_dict  = {}\n",
    "                assignment_pd_dict = {} \n",
    "                dmu_dict = {} \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                for m in range(M):\n",
    "                    treat_dict_m = permute_treatment_dict(J)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                M = 500\n",
    "                for m in range(M):\n",
    "                    w_dict_m = {} \n",
    "                    treat_dict_m = permute_treatment_dict(J)\n",
    "                    W_matrix_m = []\n",
    "                    for i in range(np.array(query_matrix).shape[0]):\n",
    "                        ## Form the consideration set \n",
    "                        each_query=np.array(query_matrix)[i,:]\n",
    "                        W_matrix_m = np.append(W_matrix_m, [[treat_dict_m[ind] for ind in each_query]])\n",
    "\n",
    "                    W_matrix_m = W_matrix_m.reshape(np.array(query_matrix).shape)\n",
    "\n",
    "\n",
    "\n",
    "                    for l in range(L):\n",
    "                        w_dict_m[l] = tf.convert_to_tensor(W_matrix_m == groupNames[l + 1], dtype = float)\n",
    "\n",
    "\n",
    "                    inputs_3d_m = tf.stack([X_goodbads,X_utility]+  [w_dict_m[l] for l in range(L)] +[X_goodbads], axis = -1)\n",
    "                    inputs_3d_test_m = inputs_3d_m[f_start:f_end,:]\n",
    "                    model_pred_m = np.array(myModelMultiple.predict(inputs_3d_test_m))[:,:k]\n",
    "                    outer_product_pv1pv2 = np.array([np.outer(row_[1:], row_[1:]) for row_ in model_pred_m])\n",
    "                    outer_product_treatment_indicator = np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                    outer_product_pv1_one_minus_pv2 = np.array([np.outer(row_, 1-row_) for row_ in model_pred_m])\n",
    "                    p_treat = 1/(L+1) \n",
    "\n",
    "                    is_selected_indicator_test = np.array(exposure_matrix[f_start:f_end,:])\n",
    "                    selected_indicator_dict[m] = is_selected_indicator_test \n",
    "                    d2l2dtheta0 = - np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "\n",
    "                    ## FIX: Iterate over l \n",
    "                    d2l2dthetal_dict = {}\n",
    "                    for l in range(L):\n",
    "                        ## K by K \n",
    "\n",
    "                        w_m_l = np.array(w_dict_m[l][f_start:f_end,:])\n",
    "\n",
    "                        ## Off-diagonal terms \n",
    "                        # d2l2dtheta1 =  np.array([np.outer(row_, row_) for row_ in w_m_l]) * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                        d2l2dtheta1 = - p_treat * p_treat * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                        ## Modify diagonal terms\n",
    "                        for i in range(d2l2dtheta1.shape[0]):\n",
    "                            treat_indicator_i = w_m_l[i,:]\n",
    "                            probs_i = model_pred_m[i,:]\n",
    "                            # np.fill_diagonal(d2l2dtheta1[i],treat_indicator_i * probs_i * (1-probs_i))\n",
    "                            np.fill_diagonal(d2l2dtheta1[i], p_treat * probs_i * (1-probs_i))\n",
    "                        d2l2dthetal_dict[l] = d2l2dtheta1\n",
    "\n",
    "\n",
    "\n",
    "                    ## FIX: iterate over all l1, l2 \n",
    "                    d2ldthetal1dthetal2 = {} \n",
    "                    for l in range(L):\n",
    "                        w_m_l = np.array(w_dict_m[l][f_start:f_end,:])\n",
    "                        ## Off-diagonal terms \n",
    "                        #d2l2dtheta0dtheta1 = - np.multiply(w_m_l[:,np.newaxis], np.array([np.outer(row_, row_) for row_ in model_pred_m]))\n",
    "                        d2l2dtheta0dtheta1 = - p_treat * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                        for i in range(d2l2dtheta0dtheta1.shape[0]):\n",
    "                            treat_indicator_i = w_m_l[i,:]\n",
    "                            p_1minusp_i = model_pred_m[i,:] * (1 - model_pred_m[i,:])\n",
    "                            #np.fill_diagonal(d2l2dtheta0dtheta1[i], treat_indicator_i * p_1minusp_i)\n",
    "                            np.fill_diagonal(d2l2dtheta0dtheta1[i], p_treat * p_1minusp_i)\n",
    "\n",
    "                        ## NOTE: -1 to indicate the baseline theta \n",
    "                        d2ldthetal1dthetal2[(-1,l)] = d2l2dtheta0dtheta1[:,1:,:]\n",
    "                        d2ldthetal1dthetal2[(l,-1)] = np.transpose(d2l2dtheta0dtheta1[:,1:,:], (0,2,1))\n",
    "                        for l_prime in range(L):\n",
    "                            if l != l_prime: \n",
    "                                #w_m_l = np.array(w_dict_m[l][training_num:,:])\n",
    "                                #w_m_l_prime = np.array(w_dict_m[l_prime][training_num:,:])\n",
    "                                #indicator_outer = np.array([np.outer(w_m_l[i,:], w_m_l_prime[i,:]) for i in range(w_m_l.shape[0])])\n",
    "\n",
    "                                #d2l2dthetal1dthetal2 = -  indicator_outer * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                                d2l2dthetal1dthetal2 = -  p_treat * p_treat * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                                d2ldthetal1dthetal2[(l,l_prime)]  = d2l2dthetal1dthetal2\n",
    "                                d2ldthetal1dthetal2[(l_prime,l)]  = np.transpose(d2l2dthetal1dthetal2, (0,2,1))\n",
    "                            else:\n",
    "                                d2ldthetal1dthetal2[(l,l)] = d2l2dthetal_dict[l]\n",
    "\n",
    "\n",
    "                    d2l2dmu = np.zeros(d2l2dtheta1.shape)\n",
    "\n",
    "                    # treatment_indicator_array_m = \n",
    "                    for i in range(d2l2dmu.shape[0]):\n",
    "                        #p_1minusp_i = (1 - model_pred_m[i,:]) * (1 - model_pred_m[i,:])\n",
    "                        p_1minusp_i = model_pred_m[i,:] * (1 - model_pred_m[i,:])\n",
    "                        # treatment_i = treatment_indicator_array[i,:]\n",
    "                        # exposure_i = is_selected_indicator_test[i,:]\n",
    "                        np.fill_diagonal(d2l2dtheta0[i], p_1minusp_i)\n",
    "                        np.fill_diagonal(d2l2dmu[i], model_pred_m[i,:])\n",
    "\n",
    "\n",
    "\n",
    "                    d2l2dtheta0 = d2l2dtheta0[:,1:, 1:]\n",
    "                    # d2l2dtheta01_k_m_1_by_k = d2l2dtheta01[:, 1:,:]\n",
    "                    # d2l2dtheta10_k_by_k_m_1 = d2l2dtheta01[:, :,1:]\n",
    "                    Hessian_first_row = np.concatenate([d2l2dtheta0] + [d2ldthetal1dthetal2[(-1, l)] for l in range(L)] + [np.zeros((d2l2dtheta0.shape[0], K-1, K))], axis =2)\n",
    "\n",
    "                    ## 1 to L + 1 row \n",
    "                    Hessian_middle_dict = {}\n",
    "                    for l in range(L):\n",
    "                        row_l = np.concatenate([d2ldthetal1dthetal2[(l, -1)]] + [d2ldthetal1dthetal2[(l, l_prime)] for l_prime in range(L)] +[np.zeros((d2l2dtheta0.shape[0], K, K))], axis =2)\n",
    "\n",
    "                        Hessian_middle_dict[l] = row_l                                                                           \n",
    "\n",
    "\n",
    "                    Hessian_third_row = np.concatenate((np.zeros((d2l2dtheta0.shape[0], K, K  * (L + 1 ) - 1 )), d2l2dmu), axis =2)\n",
    "\n",
    "                    Hessian = np.concatenate([Hessian_first_row] + [Hessian_middle_dict[l] for l in range(L)] + [Hessian_third_row], axis = 1 )\n",
    "\n",
    "                    dmu_dict[m] = d2l2dmu\n",
    "\n",
    "                    Hessian_all = Hessian_all + Hessian\n",
    "\n",
    "                Hessian_final = Hessian_all / M\n",
    "                count_finite = 0\n",
    "                score_funcs = np.zeros(len(Hessian_final))\n",
    "                for i in range(len(Hessian_final)):\n",
    "                    if is_invertible(Hessian_final[i]):\n",
    "                        try:\n",
    "                            score_funcs[i] = gradient_vector_H[i]@np.linalg.inv(Hessian_final[i])@gradient_vector_l[i]\n",
    "                            count_finite += 1 \n",
    "                        except: \n",
    "                            print(\"Fail for inversion\")\n",
    "                outs_1 = res_tempt[score_funcs !=0,K]\n",
    "\n",
    "\n",
    "                ## END OF FOR LOOP FOR EACH ITERATION OVER CROSS FITTING\n",
    "                hfuncs_f, debias_term_f = outs_1,score_funcs[score_funcs!=0]\n",
    "                # debias_point_f,  debias_var_f, undebiased_point_f  = debias_estimator(outs_1, score_funcs[score_funcs!=0])\n",
    "                # debias_point_each_fold += [debias_point_f]  \n",
    "                # debias_var_each_fold += [debias_var_f]\n",
    "                # undebiased_point_each_fold += [undebiased_point_f]\n",
    "                hfuncs_each_fold[f] =hfuncs_f\n",
    "                debias_terms_each_fold[f] = debias_term_f\n",
    "\n",
    "            tau_hat_undebias = np.mean([ np.mean(hfuncs_each_fold[f])for f in range(n_folds)])\n",
    "            tau_hat_debias = np.mean([ np.mean(hfuncs_each_fold[f] - debias_terms_each_fold[f])  for f in range(n_folds)])\n",
    "            debias_point = tau_hat_debias\n",
    "            debias_var = np.mean([debias_estimator_new(hfuncs_each_fold[f] ,debias_terms_each_fold[f], tau_hat_debias) for f in range(n_folds)])\n",
    "            undebias_point = tau_hat_undebias\n",
    "            dim_point, dim_var = dim_est(T, C)\n",
    "            dim_B += [dim_point]\n",
    "            dim_var_B += [dim_var]\n",
    "            debias_B_true += [debias_point]\n",
    "            debias_var_B_true += [debias_var]\n",
    "            undebias_B_true += [undebias_point]\n",
    "\n",
    "        result_df = pd.DataFrame({\"debias_point\": debias_B_true, \"debias_var\":debias_var_B_true, \"dim\": dim_B, \n",
    "                                 \"dim_var\":dim_var_B, \"undebias_point\": undebias_B_true, \"J\" : J,\"Q\": Q, \"K\":K })\n",
    "        result_df.to_csv(\"result2404new/synthetic_aa_j{}q{}k{}_100.csv\".format(str(J), str(Q), str(K)))\n",
    "        plt.figure() \n",
    "        sns.kdeplot(np.array(debias_B_true) / np.sqrt(np.array(debias_var_B_true)/ (int(Q/n_folds))) , shade = True,color=tencent_blue,label = \"Ours\",alpha=0.1)\n",
    "        sns.kdeplot(np.array(dim_B) / np.sqrt(np.array(dim_var_B)), shade = True,color=tencent_orange,label = \"DIM\",alpha=0.1)\n",
    "        plt.plot(x, y_standard_normal, color='black', label=\"Standard Normal\", ls='--')\n",
    "        plt.legend()\n",
    "        plt.savefig(\"result2404new/synthetic_aa_j{}q{}k{}_density.png\".format(str(J), str(Q), str(K)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07118675516242451"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Alternatively, restore results from files \n",
    "# result_pd = pd.read_csv(\"result2404new/synthetic_aa_j50q1000k5_100.csv\")\n",
    "# debias_B_true = np.array(result_pd['debias_point'])\n",
    "# debias_var_B_true = np.array(result_pd['debias_var'])\n",
    "# dim_B =  np.array(result_pd['dim'])\n",
    "# dim_var_B =  np.array(result_pd['dim_var'])\n",
    "# undebias_B_true =  np.array(result_pd['undebias_point'])\n",
    "# Q = result_pd['Q'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03933085, 0.0424891 , 0.04443004, 0.04312402, 0.0446908 ,\n",
       "       0.0443037 , 0.04640344, 0.04147065, 0.04376858, 0.04620856,\n",
       "       0.03929771, 0.04282472, 0.03754242, 0.04303195, 0.04262914,\n",
       "       0.04111774, 0.03840048, 0.04105075, 0.04195991, 0.04525505,\n",
       "       0.04003356, 0.04439367, 0.03887688, 0.04131435, 0.04249267,\n",
       "       0.04066437, 0.04143187, 0.04353405, 0.04371462, 0.04307449,\n",
       "       0.04282268, 0.04626568, 0.04389099, 0.04234505, 0.0409563 ,\n",
       "       0.04778946, 0.04402007, 0.04246734, 0.04609795, 0.0383043 ,\n",
       "       0.04760242, 0.04158091, 0.04710728, 0.04223181, 0.04509957,\n",
       "       0.04298899, 0.0437782 , 0.04477155, 0.0456346 , 0.04561083,\n",
       "       0.04373887, 0.04657138, 0.04024379, 0.04579814, 0.04229292,\n",
       "       0.0420206 , 0.03991841, 0.04828655, 0.04322153, 0.04482983,\n",
       "       0.04226   , 0.04494336, 0.04454485, 0.0409877 , 0.04144452,\n",
       "       0.04454716, 0.04598581, 0.04640789, 0.04144408, 0.04366758,\n",
       "       0.04545103, 0.04256248, 0.04519621, 0.04063017, 0.04295322,\n",
       "       0.04222496, 0.04710274, 0.04235406, 0.04496561, 0.04720344,\n",
       "       0.04392414, 0.04427486, 0.04683966, 0.03808575, 0.04164265,\n",
       "       0.04056906, 0.04625619, 0.04044562, 0.04433524, 0.0412401 ,\n",
       "       0.04400054, 0.04295576, 0.0400168 , 0.04080361, 0.04367762,\n",
       "       0.0383967 , 0.04563314, 0.04267051, 0.04080968, 0.04880414])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sns.kdeplot(np.array(debias_B_true) /  np.sqrt(np.array(debias_var_B_true)/(int(Q/n_folds))) , shade = True,color=tencent_blue,label = \"Ours(debiased)\",alpha=0.1)\n",
    "sns.kdeplot(np.array(undebias_B_true) /  np.sqrt(np.array(debias_var_B_true)/(int(Q/n_folds))) , shade = True,color='red',label = \"Ours(undebiased)\",alpha=0.1)\n",
    "sns.kdeplot(np.array(dim_B) / np.sqrt(np.array(dim_var_B)), shade = True,color=tencent_orange,label = \"DIM\",alpha=0.1)\n",
    "plt.plot(x, y_standard_normal, color='black', label=\"Standard Normal\", ls='--')\n",
    "plt.legend()\n",
    "plt.savefig(\"result2404new/comparison_estimators.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.jupyter/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/.jupyter/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff8e0238450>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(np.array(debias_B_true) /  np.sqrt(np.array(debias_var_B_true)/(int(Q/n_folds))) , shade = True,color=tencent_blue,label = \"Ours\",alpha=0.1)\n",
    "sns.kdeplot(np.array(dim_B) / np.sqrt(np.array(dim_var_B)), shade = True,color=tencent_orange,label = \"DIM\",alpha=0.1)\n",
    "plt.plot(x, y_standard_normal, color='black', label=\"Standard Normal\", ls='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debias_B_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient_vector_H[i]@np.linalg.inv(Hessian_final[i])@gradient_vector_l[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linalg.inv(Hessian_final[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debias_B_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_invertible(Hessian_final[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expos_mat = exposure_matrix_test.astype(float)\n",
    "probs_mat = model_pred_H[:, :K]\n",
    "def bootstrap_evaluation(probs_mat, expos_mat, B = 100):\n",
    "    nrows = probs_mat.shape[0]\n",
    "    kl_div_list, NDCG_list = [], []\n",
    "    for b in range(B):\n",
    "        indices = np.random.choice(nrows, size=nrows, replace=True)\n",
    "        probs_mat_b = probs_mat[indices,:]\n",
    "        expos_mat_b = expos_mat[indices,:]\n",
    "        \n",
    "        _, agg_probs_b, agg_expos_b, NDCG_b = aggregate_probability_exposure_examination(probs_mat_b, expos_mat_b)\n",
    "        kl_divergence_b = kl_div(agg_probs_b,agg_expos_b).sum()\n",
    "\n",
    "        kl_div_list += [kl_divergence_b]\n",
    "        NDCG_list += [NDCG_b]\n",
    "    return kl_div_list, NDCG_list \n",
    "kl_, ndcg_ = bootstrap_evaluation(probs_mat.astype(np.float32), expos_mat.astype(np.float32))\n",
    "\n",
    "# aggregate_probability_exposure_examination(probs_mat.astype(np.float32), expos_mat.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(ndcg_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
