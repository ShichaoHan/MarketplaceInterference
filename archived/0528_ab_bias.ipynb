{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 16:47:51.949556: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-28 16:47:52.108023: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-28 16:47:52.113364: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-28 16:47:52.113393: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-28 16:47:52.912337: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-28 16:47:52.912427: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-28 16:47:52.912438: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import Model \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import layers\n",
    "from scipy.special import kl_div\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(20240528)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_ranking as tfr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated - April Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "x = np.linspace(-4, 4, 100)\n",
    "tencent_blue = (0,0.3215686274509804,0.8509803921568627)\n",
    "tencent_orange = (0.9333333333333333, 0.49411764705882355, 0.2784313725490196)\n",
    "\n",
    "\n",
    "# Calculate y-values for the standard normal density curve\n",
    "y_standard_normal = (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_probability_exposure_examination(probs_matrix, exposure_matrix): \n",
    "    aggregate_probs = np.mean(probs_matrix, axis = 0)\n",
    "    exposure_probs = np.mean(exposure_matrix, axis = 0)\n",
    "    ## Euclidean distance \n",
    "    euc_dist = np.linalg.norm(aggregate_probs - exposure_probs)\n",
    "    ## NDCG LOSS \n",
    "    y_true = tf.ragged.constant(exposure_matrix)\n",
    "    y_pred = tf.ragged.constant(probs_matrix)\n",
    "    loss_NDCG = tfr.keras.losses.ApproxNDCGLoss(ragged=True)\n",
    "    NDCG_loss_result = loss_NDCG(y_true, y_pred).numpy()\n",
    "    return euc_dist, aggregate_probs, exposure_probs, NDCG_loss_result\n",
    "def mySoftMax(arr):\n",
    "    num = np.exp(arr)\n",
    "    denom = np.sum(num)\n",
    "    return num/denom\n",
    "\n",
    "\n",
    "def naive_est(res):\n",
    "    treat_res = [elm[0] for elm in res[0]]\n",
    "    control_res = [elm[1] for elm in res[0]]\n",
    "    return np.mean(treat_res) - np.mean(control_res)\n",
    "\n",
    "\n",
    "def dim_est(obs_T, obs_C):\n",
    "    n1,n0 = len(obs_T), len(obs_C)\n",
    "    return np.mean(obs_T) -np.mean(obs_C), np.sqrt(np.var(obs_T)/n1 + np.var(obs_C) / n0)\n",
    "\n",
    "\n",
    "def point_est(all_treat_array, all_control_array):\n",
    "    mus_T, mus_C  = all_treat_array[:, 11:21], all_control_array[:,11:21]\n",
    "    p_T, p_C  = all_treat_array[:, 21:], all_control_array[:,21:]\n",
    "    return np.mean(np.sum((mus_T * (p_T - p_C)), axis = 1 ))\n",
    "\n",
    "\n",
    "def naive_dim_estimate(vector_T, vector_C):\n",
    "    return np.mean(vector_T) - np.mean(vector_C), np.var(vector_T)/len(vector_T) + np.var(vector_C) / len(vector_C)\n",
    "\n",
    "def debias_estimator(Hfuncs, debias_terms):\n",
    "    score_functions = Hfuncs - debias_terms \n",
    "    undebiased_estimator = np.mean(Hfuncs)\n",
    "    debiased_estimator = np.mean(score_functions)\n",
    "    variance_estimator = np.mean((score_functions - debiased_estimator)**2) /len(score_functions)\n",
    "    return debiased_estimator, variance_estimator, undebiased_estimator \n",
    "\n",
    "def debias_estimator_new(Hfuncs, debias_terms,tau_hat):\n",
    "    psi_functions = Hfuncs - debias_terms \n",
    "    undebiased_estimator = np.mean(Hfuncs)\n",
    "    debiased_estimator = np.mean(psi_functions)\n",
    "    variance_estimator = np.sum((psi_functions - tau_hat)**2) /len(psi_functions)\n",
    "    return debiased_estimator, variance_estimator, undebiased_estimator \n",
    "\n",
    "\n",
    "def undebias_estimator_new(Hfuncs,tau_hat):\n",
    "    psi_functions = Hfuncs \n",
    "    undebiased_estimator = np.mean(Hfuncs)\n",
    "    variance_estimator = np.sum((psi_functions - tau_hat)**2) /len(psi_functions)\n",
    "    \n",
    "    return undebiased_estimator, variance_estimator \n",
    "\n",
    "\n",
    "def is_invertible(matrix):\n",
    "    return np.linalg.det(matrix) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of videos \n",
    "J = 20 \n",
    "## Consideration set size \n",
    "K = 5 \n",
    "k=5\n",
    "## Generate some queries along with the recommendation model \n",
    "Q = 800\n",
    "\n",
    "\n",
    "def permute_treatment_dict(J):\n",
    "    perm_dict = {}\n",
    "    for j in range(J):\n",
    "        perm_dict[j] = np.random.choice([True,False], 1)\n",
    "    return perm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generating Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## True Exposure Model and Data Generating Process \n",
    "def logistic_row(row):\n",
    "    return np.exp(row) / np.sum(np.exp(row))\n",
    "\n",
    "\n",
    "\n",
    "def DGP_new_heterogeneous(J, Q, K, promo_ratio, query_matrix, selected_indices, X_goodbads, X_utility,  treat_control_pool = [True, False]):\n",
    "    ## Randomize over the treatment assignment matrix; random noise being added to the potential outcome  \n",
    "    treatment_dict = {}\n",
    "    for j in range(J):\n",
    "        treatment_dict[j] = np.random.choice(treat_control_pool, 1)\n",
    "\n",
    "    W_matrix = []\n",
    "    for each_query in range(Q):\n",
    "         W_matrix = np.append(W_matrix, [treatment_dict[ind] for ind in selected_indices])\n",
    "\n",
    "    outcome_noise =  np.random.normal(size=(Q, K)) \n",
    "    W_matrix = W_matrix.reshape(Q,K)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    final_score_matrix = W_matrix * promo_ratio * X_goodbads +  X_utility\n",
    "\n",
    "    X_logit = np.apply_along_axis(logistic_row, axis=1, arr=final_score_matrix)\n",
    "    expose_indices = np.array([np.random.choice(np.arange(K), size = 1, p = X_logit[i,:]) for i in range(Q)])\n",
    "    inddds = np.array(list(np.arange(K)) * Q).reshape(Q,K)\n",
    "    exposure_matrix = np.array([inddds[i,:] == expose_indices[i] for i in range(Q)])\n",
    "\n",
    "    ## Outcome model  \n",
    "    ## First: a true outcome model of Exponential \n",
    "    outcome_potential = outcome_noise +  X_utility\n",
    "\n",
    "    return query_matrix,X_goodbads,X_utility,W_matrix, exposure_matrix, outcome_potential\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def DGP_new_homogeneous(J, Q, K, promo_ratio, query_matrix, selected_indices, X_goodbads, X_utility, treat_control_pool = [True, False]):\n",
    "    ## Randomize over the treatment assignment matrix \n",
    "    treatment_dict = {}\n",
    "    for j in range(J):\n",
    "        treatment_dict[j] = np.random.choice(treat_control_pool, 1)\n",
    "\n",
    "    W_matrix = []\n",
    "    for each_query in range(Q):\n",
    "         W_matrix = np.append(W_matrix, [treatment_dict[ind] for ind in selected_indices])\n",
    "\n",
    "    outcome_noise =  np.random.normal(size=(Q, K)) \n",
    "    W_matrix = W_matrix.reshape(Q,K)\n",
    "    # W_matrix = W_matrix.reshape(Q,K)\n",
    "    final_score_matrix = W_matrix * promo_ratio   + X_utility\n",
    "\n",
    "    X_logit = np.apply_along_axis(logistic_row, axis=1, arr=final_score_matrix)\n",
    "    expose_indices = np.array([np.random.choice(np.arange(K), size = 1, p = X_logit[i,:]) for i in range(Q)])\n",
    "    inddds = np.array(list(np.arange(K)) * Q).reshape(Q,K)\n",
    "    exposure_matrix = np.array([inddds[i,:] == expose_indices[i] for i in range(Q)])\n",
    "\n",
    "    ## Outcome model  \n",
    "    ## First: a true outcome model of Exponential \n",
    "    outcome_potential = outcome_noise +  X_utility\n",
    "\n",
    "    return query_matrix,X_goodbads,X_utility,W_matrix, exposure_matrix, outcome_potential\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def DGP_new_heterogeneous_counterfactual(J, Q, K, promo_ratio, query_matrix, selected_indices, X_goodbads, X_utility,  treat_control_pool = [True, False]):\n",
    "    ## Randomize over the treatment assignment matrix; random noise being added to the potential outcome  \n",
    "    treatment_dict = {}\n",
    "    for j in range(J):\n",
    "        treatment_dict[j] = np.random.choice(treat_control_pool, 1)\n",
    "\n",
    "    W_matrix = []\n",
    "    for each_query in range(Q):\n",
    "         W_matrix = np.append(W_matrix, [treatment_dict[ind] for ind in selected_indices])\n",
    "\n",
    "    outcome_noise =  np.random.normal(size=(Q, K)) \n",
    "    W_matrix = W_matrix.reshape(Q,K)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    final_score_matrix = W_matrix * promo_ratio * X_goodbads +  X_utility\n",
    "\n",
    "    X_logit = np.apply_along_axis(logistic_row, axis=1, arr=final_score_matrix)\n",
    "    expose_indices = np.array([np.random.choice(np.arange(K), size = 1, p = X_logit[i,:]) for i in range(Q)])\n",
    "    inddds = np.array(list(np.arange(K)) * Q).reshape(Q,K)\n",
    "    exposure_matrix = np.array([inddds[i,:] == expose_indices[i] for i in range(Q)])\n",
    "\n",
    "    ## Outcome model  \n",
    "    ## First: a true outcome model of Exponential \n",
    "    outcome_potential = outcome_noise +  X_utility\n",
    "\n",
    "    return query_matrix,X_goodbads,X_utility,W_matrix, exposure_matrix, outcome_potential, X_logit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def DGP_new_homogeneous_counterfactual(J, Q, K, promo_ratio, query_matrix, selected_indices, X_goodbads, X_utility, treat_control_pool = [True, False]):\n",
    "    ## Randomize over the treatment assignment matrix \n",
    "    treatment_dict = {}\n",
    "    for j in range(J):\n",
    "        treatment_dict[j] = np.random.choice(treat_control_pool, 1)\n",
    "\n",
    "    W_matrix = []\n",
    "    for each_query in range(Q):\n",
    "         W_matrix = np.append(W_matrix, [treatment_dict[ind] for ind in selected_indices])\n",
    "\n",
    "    outcome_noise =  np.random.normal(size=(Q, K)) \n",
    "    W_matrix = W_matrix.reshape(Q,K)\n",
    "    # W_matrix = W_matrix.reshape(Q,K)\n",
    "    final_score_matrix = W_matrix * promo_ratio   + X_utility\n",
    "\n",
    "    X_logit = np.apply_along_axis(logistic_row, axis=1, arr=final_score_matrix)\n",
    "    expose_indices = np.array([np.random.choice(np.arange(K), size = 1, p = X_logit[i,:]) for i in range(Q)])\n",
    "    inddds = np.array(list(np.arange(K)) * Q).reshape(Q,K)\n",
    "    exposure_matrix = np.array([inddds[i,:] == expose_indices[i] for i in range(Q)])\n",
    "\n",
    "    ## Outcome model  \n",
    "    ## First: a true outcome model of Exponential \n",
    "    outcome_potential = outcome_noise +  X_utility\n",
    "\n",
    "    return query_matrix,X_goodbads,X_utility,W_matrix, exposure_matrix, outcome_potential, X_logit\n",
    "\n",
    "# I. deterministic: \n",
    "# selected_indices = np.argmax(X_logit, axis = 1)\n",
    "# II. random choice for exposure \n",
    "\n",
    "def DGP(promo_rat, K,Q, J, utility_matrix=None):\n",
    "    ## Generate a utility score for each viewer and video pair\n",
    "    if utility_matrix is None: \n",
    "        utility_score_matrix = np.exp(np.random.normal(size=(Q,J)))\n",
    "    else:\n",
    "        utility_score_matrix = utility_matri\n",
    "    good_bad_dict = {} \n",
    "    treatment_dict = {} \n",
    "    utility_score = {} \n",
    "    for j in range(J):\n",
    "        good_bad_dict[j] = np.random.choice([True,False], 1)\n",
    "        treatment_dict[j] = np.random.choice([True,False], 1)\n",
    "        utility_score[j] = np.random.uniform()\n",
    "    X_goodbads = []\n",
    "    X_utility = []\n",
    "    W_matrix = []\n",
    "    query_matrix = []\n",
    "    promo_ratio = promo_rat\n",
    "    for each_query in range(Q):\n",
    "        ## Form the consideration set \n",
    "        selected_indices = np.random.choice(np.arange(J), K, replace= False)\n",
    "        query_matrix += [selected_indices]\n",
    "        X_goodbads = np.append(X_goodbads,[good_bad_dict[ind] for ind in selected_indices])\n",
    "        X_utility = np.append(X_utility, [utility_score_matrix[each_query, ind] for ind in selected_indices])\n",
    "        W_matrix = np.append(W_matrix, [treatment_dict[ind] for ind in selected_indices])\n",
    "    X_goodbads = X_goodbads.reshape(Q, K)\n",
    "    X_utility = X_utility.reshape(Q, K)\n",
    "    X_utility = X_utility + X_goodbads \n",
    "    W_matrix = W_matrix.reshape(Q,K)\n",
    "    final_score_matrix = (1 + W_matrix * promo_ratio * X_goodbads) * X_utility\n",
    "\n",
    "    X_logit = np.apply_along_axis(logistic_row, axis=1, arr=final_score_matrix)\n",
    "    expose_indices = np.array([np.random.choice(np.arange(K), size = 1, p = X_logit[i,:]) for i in range(Q)])\n",
    "    inddds = np.array(list(np.arange(K)) * Q).reshape(Q,K)\n",
    "    exposure_matrix = np.array([inddds[i,:] == expose_indices[i] for i in range(Q)])\n",
    "\n",
    "    ## Outcome model  \n",
    "    ## First: a true outcome model of Exponential \n",
    "    outcome_potential = np.random.normal(size=(Q, K)) +  X_utility\n",
    "\n",
    "    return query_matrix,X_goodbads,X_utility,W_matrix, exposure_matrix, outcome_potential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGP_with_counter_factual(promo_rat, K,Q, J):\n",
    "    ## Generate a utility score for each viewer and video pair\n",
    "    utility_score_matrix = np.exp(np.random.normal(size=(Q,J)))\n",
    "    good_bad_dict = {} \n",
    "    treatment_dict = {} \n",
    "    utility_score = {} \n",
    "    for j in range(J):\n",
    "        good_bad_dict[j] = np.random.choice([True,False], 1)\n",
    "        treatment_dict[j] = np.random.choice([True,False], 1)\n",
    "        utility_score[j] = np.random.uniform()\n",
    "    X_goodbads = []\n",
    "    X_utility = []\n",
    "    W_matrix = []\n",
    "    query_matrix = []\n",
    "    promo_ratio = promo_rat\n",
    "    for each_query in range(Q):\n",
    "        ## Form the consideration set \n",
    "        selected_indices = np.random.choice(np.arange(J), K, replace= False)\n",
    "        query_matrix += [selected_indices]\n",
    "        X_goodbads = np.append(X_goodbads,[good_bad_dict[ind] for ind in selected_indices])\n",
    "        X_utility = np.append(X_utility, [utility_score_matrix[each_query, ind] for ind in selected_indices])\n",
    "        W_matrix = np.append(W_matrix, [treatment_dict[ind] for ind in selected_indices])\n",
    "    X_goodbads = X_goodbads.reshape(Q, K)\n",
    "    X_utility = X_utility.reshape(Q, K)\n",
    "    X_uitlity = X_utility + X_goodbads \n",
    "    W_matrix = W_matrix.reshape(Q,K)\n",
    "    final_score_matrix = (1 + W_matrix * promo_ratio * X_goodbads) * X_utility\n",
    "    ## Add counterfactuals \n",
    "    final_score_treat = (1 +   promo_ratio * X_goodbads ) * X_utility\n",
    "    final_score_control = X_utility \n",
    "    \n",
    "    \n",
    "    X_logit = np.apply_along_axis(logistic_row, axis=1, arr=final_score_matrix)\n",
    "    ## Add counterfactuals \n",
    "    X_logit_treat = np.apply_along_axis(logistic_row, axis=1, arr=final_score_treat)\n",
    "    X_logit_control = np.apply_along_axis(logistic_row, axis=1, arr=final_score_control)\n",
    "    \n",
    "    \n",
    "    expose_indices = np.array([np.random.choice(np.arange(K), size = 1, p = X_logit[i,:]) for i in range(Q)])\n",
    "    inddds = np.array(list(np.arange(K)) * Q).reshape(Q,K)\n",
    "    exposure_matrix = np.array([inddds[i,:] == expose_indices[i] for i in range(Q)])\n",
    "    \n",
    "    expose_indices_treat = np.array([np.random.choice(np.arange(K), size = 1, p = X_logit_treat[i,:]) for i in range(Q)])\n",
    "    exposure_matrix_treat = np.array([inddds[i,:] == expose_indices_treat[i] for i in range(Q)])\n",
    "    \n",
    "    expose_indices_control = np.array([np.random.choice(np.arange(K), size = 1, p = X_logit_control[i,:]) for i in range(Q)])\n",
    "    exposure_matrix_control = np.array([inddds[i,:] == expose_indices_control[i] for i in range(Q)])\n",
    "\n",
    "    ## Outcome model  \n",
    "    ## First: a true outcome model of Exponential \n",
    "    outcome_potential = np.random.normal(size=(Q, K)) +  X_utility \n",
    "\n",
    "    return query_matrix,X_goodbads,X_utility,W_matrix, exposure_matrix, outcome_potential, exposure_matrix_treat, exposure_matrix_control \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## True Model \n",
    "\n",
    "class MyModel_True_Heterogeneous:\n",
    "    def __init__(self, k, num_treats,promo_ratio):\n",
    "\n",
    "        self.k = k\n",
    "        self.promo_ratio = promo_ratio\n",
    "        self.num_treats = num_treats\n",
    "\n",
    "    def predict(self,inputs):\n",
    "        Q_input = inputs.shape[0]\n",
    "        split_structure =  [1]+ [1] + [1] * self.num_treats + [1]\n",
    "        splitted_elements = tf.split(inputs, split_structure, axis=2)\n",
    "        X_utility =  np.squeeze(np.array(splitted_elements[1]), axis=2)\n",
    "        X_goodbads = np.squeeze(np.array(splitted_elements[0]), axis = 2)\n",
    "\n",
    "        W_matrix =  np.squeeze(np.array(splitted_elements[2]), axis =2 )\n",
    "\n",
    "        final_score_matrix =  W_matrix * self.promo_ratio * X_goodbads + X_utility\n",
    "\n",
    "        ## First element of each row \n",
    "        first_elm = X_utility[:,0]\n",
    "        minus_matrix = first_elm.reshape((len(first_elm),1))@np.ones((1,K))\n",
    "        final_score_matrix_normalized = final_score_matrix - minus_matrix\n",
    "        ## Correct exposure probability \n",
    "        X_logit = np.apply_along_axis(logistic_row, axis=1, arr=final_score_matrix_normalized)\n",
    "    \n",
    "        expose_indices = np.argmax(X_logit, axis = 1)\n",
    "        inddds = np.array(list(np.arange(K)) * Q_input).reshape(Q_input,K)\n",
    "        exposure_matrix = np.array([inddds[i,:] == expose_indices[i] for i in range(Q_input)])\n",
    "\n",
    "        ## Outcome model  \n",
    "        \n",
    "        ## First: a true outcome model of Exponential \n",
    "        outcome_potential = X_utility\n",
    "        pred_out = np.sum(exposure_matrix * outcome_potential, axis = 1 )\n",
    "        pred_out = pred_out.reshape(pred_out.shape[0], 1 )\n",
    "        return np.concatenate([X_logit, pred_out], axis = 1 )\n",
    "    \n",
    "class MyModel_True_Homogeneous:\n",
    "    def __init__(self, k, num_treats,promo_ratio):\n",
    "\n",
    "        self.k = k\n",
    "        self.promo_ratio = promo_ratio\n",
    "        self.num_treats = num_treats\n",
    "\n",
    "    def predict(self,inputs):\n",
    "        Q_input = inputs.shape[0]\n",
    "        split_structure =  [1]+ [1] + [1] * self.num_treats + [1]\n",
    "        splitted_elements = tf.split(inputs, split_structure, axis=2)\n",
    "        X_utility =  np.squeeze(np.array(splitted_elements[1]), axis=2)\n",
    "        X_goodbads = np.squeeze(np.array(splitted_elements[0]), axis = 2)\n",
    "\n",
    "        W_matrix =  np.squeeze(np.array(splitted_elements[2]), axis =2 )\n",
    "\n",
    "        final_score_matrix = W_matrix * self.promo_ratio + X_utility\n",
    "\n",
    "        ## First element of each row \n",
    "        first_elm = X_utility[:,0]\n",
    "        minus_matrix = first_elm.reshape((len(first_elm),1))@np.ones((1,K))\n",
    "        final_score_matrix_normalized = final_score_matrix - minus_matrix\n",
    "        ## Correct exposure probability \n",
    "        X_logit = np.apply_along_axis(logistic_row, axis=1, arr=final_score_matrix_normalized)\n",
    "    \n",
    "        expose_indices = np.argmax(X_logit, axis = 1)\n",
    "        inddds = np.array(list(np.arange(K)) * Q_input).reshape(Q_input,K)\n",
    "        exposure_matrix = np.array([inddds[i,:] == expose_indices[i] for i in range(Q_input)])\n",
    "\n",
    "        ## Outcome model  \n",
    "        \n",
    "        ## First: a true outcome model of Exponential \n",
    "        outcome_potential = X_utility\n",
    "        pred_out = np.sum(exposure_matrix * outcome_potential, axis = 1 )\n",
    "        pred_out = pred_out.reshape(pred_out.shape[0], 1 )\n",
    "        return np.concatenate([X_logit, pred_out], axis = 1 )\n",
    "## True Model \n",
    "\n",
    "class MyModel_Random:\n",
    "    def __init__(self, k, num_treats,promo_ratio):\n",
    "\n",
    "        self.k = k\n",
    "        self.promo_ratio = promo_ratio\n",
    "        self.num_treats = num_treats\n",
    "\n",
    "    def predict(self,inputs):\n",
    "        output_shape = np.array(input_3d_test_treat.shape)[:2]\n",
    "        array = np.random.rand(output_shape[0],output_shape[1])\n",
    "        # Compute the sum of each row\n",
    "        row_sums = np.sum(array, axis=1)\n",
    "\n",
    "        # Reshape the row sums to make them compatible for broadcasting\n",
    "        row_sums = row_sums.reshape(-1, 1)\n",
    "\n",
    "        normalized_array = array / row_sums\n",
    "\n",
    "        return normalized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "utility_score_matrix = np.exp(np.random.normal(size=(Q,J)))\n",
    "\n",
    "good_bad_dict = {} \n",
    "treatment_dict = {} \n",
    "utility_score = {} \n",
    "for j in range(J):\n",
    "    good_bad_dict[j] = np.random.choice([True,False], 1)\n",
    "    utility_score[j] = np.random.uniform()\n",
    "X_goodbads = []\n",
    "X_utility = []\n",
    "query_matrix = []\n",
    "for each_query in range(Q):\n",
    "    ## Form the consideration set \n",
    "    selected_indices = np.random.choice(np.arange(J), K, replace= False)\n",
    "    query_matrix += [selected_indices]\n",
    "    X_goodbads = np.append(X_goodbads,[good_bad_dict[ind] for ind in selected_indices])\n",
    "    X_utility = np.append(X_utility, [utility_score_matrix[each_query, ind] for ind in selected_indices])\n",
    "X_goodbads = X_goodbads.reshape(Q, K)\n",
    "X_utility = X_utility.reshape(Q, K)\n",
    "X_utility = X_utility + X_goodbads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_matrix_T,X_goodbads_T,X_utility_T,W_matrix_T, exposure_matrix_T, outcome_potential_T, X_logit_T = DGP_new_heterogeneous_counterfactual(J, Q, K, 1, query_matrix, selected_indices, X_goodbads, X_utility,  treat_control_pool = [True, True])\n",
    "\n",
    "\n",
    "\n",
    "query_matrix_C,X_goodbads_C,X_utility_C,W_matrix_C, exposure_matrix_C, outcome_potential_C, X_logit_C= DGP_new_heterogeneous_counterfactual(J, Q, K, 1, query_matrix, selected_indices, X_goodbads, X_utility,  treat_control_pool = [False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_gt = np.sum(X_logit_T * X_utility , axis = 1 )\n",
    "C_gt = np.sum(X_logit_C * X_utility , axis = 1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = np.mean(T_gt) - np.mean(C_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function for cross validation\n",
    "def generate_indices(n, K):\n",
    "    ## Split original sample of size n into K sets \n",
    "    indices = np.linspace(0, n, K+1, dtype=int)\n",
    "    return list(zip(indices[:-1], indices[1:]))\n",
    "\n",
    "\n",
    "def train_test_split(input_data, all_inds, kth_test):\n",
    "    \n",
    "    training_ind = [all_inds[i] for i in range(len(all_inds)) if i != kth_test]\n",
    "    test_start, test_end = all_inds[kth_test]\n",
    "    if not tf.is_tensor(input_data):\n",
    "        training_data = np.concatenate([input_data[elm[0]:elm[1]] for elm in training_ind])\n",
    "    else:\n",
    "        \n",
    "        training_data = tf.concat([input_data[elm[0]:elm[1]] for elm in training_ind], axis = 0)\n",
    "    testing_data = input_data[test_start:test_end]\n",
    "    return training_data, testing_data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start K = 5, Q = 800, J = 30\n",
      "0\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.jupyter/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/.jupyter/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/.jupyter/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3724: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/opt/.jupyter/lib/python3.7/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in true_divide\n",
      "  subok=False)\n",
      "/opt/.jupyter/lib/python3.7/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "20\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "40\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 993us/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 998us/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "60\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 997us/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "80\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "dim_B, dim_var_B= [],[]\n",
    "debias_B_true, debias_var_B_true = [],[] \n",
    "undebias_B_true, debias_var_old_B_true = [],[]\n",
    "truth= []\n",
    "undebias_var_B_true = []\n",
    "## Number of iterations of DGP\n",
    "B = 100\n",
    "## Number of videos \n",
    "JQ_sizes = [(50,1000), (100,1000), (200, 1000)]\n",
    "training_ratio = 0.4\n",
    "\n",
    "num_features = 2 \n",
    "\n",
    "## Consideration set size \n",
    "Ks = [5,10,20]\n",
    "\n",
    "JQ_sizes = [(30,800)]\n",
    "Ks = [5]\n",
    "\n",
    "\n",
    "for (J, Q) in JQ_sizes:\n",
    "    for K in Ks:\n",
    "        print(\"Start K = {}, Q = {}, J = {}\".format(str(K), str(Q), str(J)))\n",
    "        dim_B, dim_var_B= [],[]\n",
    "        debias_B_true, debias_var_B_true = [],[] \n",
    "        undebias_B_true, debias_var_old_B_true = [],[]\n",
    "        truth= []\n",
    "\n",
    "\n",
    "        ## True Outcome Model test \n",
    "        L = 1\n",
    "        ith_treat = 0\n",
    "        M = 100\n",
    "        groupNames = [0,1]\n",
    "        uplift_ratio = 1\n",
    "        k = K\n",
    "        n_folds = 3\n",
    "        for b in range(B):\n",
    "            if b % 20 == 0:\n",
    "                print(b)\n",
    "            ## DGP and data pre-processing \n",
    "            query_matrix,X_goodbads,X_utility,W_matrix, exposure_matrix, outcome_potential= DGP_new_heterogeneous(J, Q, K, uplift_ratio, query_matrix, selected_indices, X_goodbads, X_utility, treat_control_pool = [True, False])\n",
    "\n",
    "            ## Fix in v2: add cross-fitting to the code \n",
    "            all_inds = generate_indices(np.array(query_matrix).shape[0], n_folds)\n",
    "            \n",
    "\n",
    "            ## Iterate over each fold for cross-validation. \n",
    "\n",
    "            hfuncs_each_fold,  debias_terms_each_fold = {},{}\n",
    "            for f in range(n_folds):\n",
    "                f_start, f_end = all_inds[f]\n",
    "                query_train, query_test = train_test_split(np.array(query_matrix), all_inds, f)\n",
    "                X_goodbads_train, X_goodbads_test =  train_test_split(X_goodbads, all_inds, f) \n",
    "                X_utility_train, X_utility_test =  train_test_split(X_utility, all_inds, f)  \n",
    "                W_matrix_train, W_matrix_test = train_test_split(W_matrix, all_inds, f) \n",
    "                observed_queries_treatment = np.sum(exposure_matrix * W_matrix, axis = 1 )\n",
    "                observed_outcome = np.sum(outcome_potential * exposure_matrix, axis = 1 )\n",
    "\n",
    "                T, C = observed_outcome[observed_queries_treatment == groupNames[ith_treat + 1 ]] , observed_outcome[observed_queries_treatment == 0]  \n",
    "                exposure_matrix_train,exposure_matrix_test =train_test_split(exposure_matrix, all_inds, f) \n",
    "                outcome_matrix = exposure_matrix * outcome_potential\n",
    "                outcome_matrix = np.sum(outcome_matrix, axis = 1 ).reshape(outcome_matrix.shape[0],1)\n",
    "\n",
    "                observed_outcome_train, observed_outcome_test = train_test_split(observed_outcome, all_inds, f) \n",
    "                outcome_matrix_train, outcome_matrix_test = train_test_split(outcome_matrix, all_inds, f) \n",
    "                outcome_potential_train, outcome_potential_test = train_test_split(outcome_potential, all_inds, f)  \n",
    "                inputs_3d_train = tf.stack([X_goodbads_train,X_utility_train, W_matrix_train, X_utility_train ], axis = -1)\n",
    "                inputs_3d_test = tf.stack([X_goodbads_test,X_utility_test, W_matrix_test, X_utility_test], axis = -1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                input_3d_test_treat = tf.stack([X_goodbads_test,X_utility_test, np.ones(W_matrix_test.shape), X_utility_test], axis = -1)\n",
    "                input_3d_test_control = tf.stack([X_goodbads_test,X_utility_test, np.zeros(W_matrix_test.shape), X_utility_test], axis = -1)\n",
    "                output_3d_train = tf.concat([tf.cast(exposure_matrix_train, dtype=float),outcome_matrix_train], axis = 1)\n",
    "                output_3d_test = tf.concat([tf.cast(exposure_matrix_test, dtype=float),outcome_matrix_test ], axis = 1)\n",
    "\n",
    "                exposure_indicator_array = exposure_matrix_test\n",
    "\n",
    "\n",
    "                ## Get treatment indicator matrix\n",
    "                w_dict = {}\n",
    "\n",
    "                for l in range(L):\n",
    "                    w_dict[l] = tf.convert_to_tensor(W_matrix == groupNames[l+1], dtype = float)\n",
    "\n",
    "                training_num = int(W_matrix.shape[0] * training_ratio)\n",
    "                testing_num = W_matrix.shape[0] - training_num\n",
    "\n",
    "\n",
    "                w_all_treat = tf.convert_to_tensor(np.array([[1] * k for _ in range(W_matrix.shape[0])],dtype='float32'))\n",
    "                w_all_control = tf.convert_to_tensor(np.array([[0] * k for _ in range(W_matrix.shape[0])],dtype='float32'))\n",
    "\n",
    "                inputs_all_treat_3d = tf.stack([X_goodbads,X_utility] + [w_all_treat if l == ith_treat else w_all_control for l in range(L)] +[ X_utility], axis = 2)\n",
    "                inputs_all_control_3d = tf.stack([X_goodbads,X_utility] + [w_all_control if l == ith_treat else w_all_control for l in range(L)] +[ X_utility ], axis = 2)\n",
    "                inputs_all_treat_3d = tf.cast(inputs_all_treat_3d, dtype = 'float32')\n",
    "                inputs_all_control_3d = tf.cast(inputs_all_control_3d, dtype = 'float32')\n",
    "\n",
    "                ## All other all_treated \n",
    "                inputs_all_treat_3d_dict = {} \n",
    "                for l in range(L):\n",
    "                    inputs_all_treat_3d_l = tf.stack([X_goodbads,X_utility] + [w_all_treat if l == v else w_all_control for v in range(L)] +[ X_utility ], axis = 2)\n",
    "                    #inputs_all_treat_3d_l = tf.stack([x_basebid, x_sort_score, x_bid,x_ecpm, x_cvr] + [w_all_treat if v == l else w_all_control for v in range(L)] + [x_cvr], axis = 2)\n",
    "                    inputs_all_treat_3d_dict[l] = tf.cast(inputs_all_treat_3d_l, dtype = 'float32')\n",
    "\n",
    "                exposure_indicator_outcome_train, exposure_indicator_outcome_test = outcome_matrix_train, outcome_matrix_test\n",
    "                inputs_all_treat_3d_test = input_3d_test_treat\n",
    "                inputs_all_control_3d_test = input_3d_test_control\n",
    "                is_selected_indicator_train,is_selected_indicator_test = exposure_matrix_train,exposure_matrix_test\n",
    "\n",
    "                treat_control_dict = {} \n",
    "                for l in range(L):\n",
    "\n",
    "                    \n",
    "                    inputs_3d_train_l,inputs_3d_test_l= train_test_split(inputs_all_treat_3d_dict[l], all_inds, f) \n",
    "\n",
    "                    treat_control_dict[l] = {'train':inputs_3d_train_l, 'test': inputs_3d_test_l}\n",
    "\n",
    "                myModelMultiple = MyModel_True_Heterogeneous(K, L, uplift_ratio)\n",
    "                myModelMultiple_random = MyModel_Random(K, L, uplift_ratio)\n",
    "                # myModelMultiple.compile(loss=custom_loss,optimizer=tf.keras.optimizers.legacy.Adam())\n",
    "                # myModelMultiple.fit(input_3d_train,output_3d_train , epochs=10, verbose=False)\n",
    "                exposure_indicator_array = is_selected_indicator_test\n",
    "                treatment_indicator_array = 1 * (np.array(w_dict[ith_treat])[f_start:f_end,:])\n",
    "\n",
    "                res_tempt = np.array(myModelMultiple.predict(inputs_all_treat_3d_test)) - np.array(myModelMultiple.predict(inputs_all_control_3d_test))\n",
    "\n",
    "\n",
    "                pred_H_new = np.array(myModelMultiple.predict(inputs_all_treat_3d_test)) - np.array(myModelMultiple.predict(inputs_all_control_3d_test))\n",
    "                model_pred_H = np.array(myModelMultiple.predict(inputs_3d_test))\n",
    "                model_pred_all_treat = myModelMultiple.predict(inputs_all_treat_3d_test)\n",
    "                model_pred_all_control = myModelMultiple.predict(inputs_all_control_3d_test)\n",
    "                all_treat_array, all_control_array = np.array(model_pred_all_treat), np.array(model_pred_all_control)\n",
    "\n",
    "                ## All other counterfactuals \n",
    "                counterfactual_pred_dict = {} \n",
    "                for l in range(L):\n",
    "                    model_pred_all_l = myModelMultiple.predict(treat_control_dict[l]['test'])\n",
    "                    counterfactual_pred_dict[l] = model_pred_all_l\n",
    "\n",
    "                ## Outcome - prediction model \n",
    "                indicator_bool = tf.cast(is_selected_indicator_train, dtype=tf.bool)\n",
    "                selected_elements = tf.boolean_mask(inputs_3d_train[:,:,:num_features], indicator_bool)\n",
    "\n",
    "                input_to_outcomemodel_train = tf.reshape(selected_elements, (inputs_3d_train.shape[0], num_features))\n",
    "                # Define your base model\n",
    "                base_model = tf.keras.Sequential()\n",
    "                base_model.add(layers.Dense(1, input_shape=(num_features,)))\n",
    "\n",
    "                # Compile the model\n",
    "                base_model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "                base_model.fit(input_to_outcomemodel_train,output_3d_train[:, K],epochs=50, verbose=False)\n",
    "                # Now define a new model for prediction\n",
    "                model_for_prediction = tf.keras.Sequential()\n",
    "                model_for_prediction.add(layers.TimeDistributed(base_model, input_shape=(K, num_features)))\n",
    "                predictions = model_for_prediction.predict(inputs_3d_test[:,:,:num_features])\n",
    "                # Remove the third dimension of size 1\n",
    "                numpy_array_pred = np.squeeze(predictions, axis=2)\n",
    "\n",
    "                mus_T, mus_C  = numpy_array_pred,numpy_array_pred\n",
    "                p_T, p_C  = all_treat_array[:, :k], all_control_array[:,:k]\n",
    "                rewards_array = observed_outcome_test\n",
    "                rewards_array = rewards_array.reshape(rewards_array.shape[0],1)\n",
    "                Ey1,Ey0 = np.sum(mus_T * p_T, axis = 1), np.sum(mus_C * p_C, axis = 1)\n",
    "                pv1,pv0 = np.sum(exposure_indicator_array * p_T, axis = 1), np.sum(exposure_indicator_array * p_C, axis = 1)\n",
    "\n",
    "                pv_given_uvw = p_T * treatment_indicator_array + p_C * (1 - treatment_indicator_array)\n",
    "\n",
    "\n",
    "                p_realized = model_pred_H[:,:K]\n",
    "\n",
    "\n",
    "\n",
    "                ## 1. COMPUTE THE GRADIENT OF LOSSS  \n",
    "                ## FIX: change to realized outcome \n",
    "                #dl1dtheta0 = pv_given_uvw - exposure_indicator_array\n",
    "                dl1dtheta0 = p_realized - exposure_indicator_array\n",
    "                dl1dtheta0 = dl1dtheta0[:, 1:] \n",
    "\n",
    "\n",
    "                ## FIX: iterate over all L \n",
    "                dl1dthetal_dict = {} \n",
    "                for l in range(L):\n",
    "                    treatment_indicator_array_l = w_dict[l][f_start:f_end, :]\n",
    "                    dl1dthetal_dict[l] = treatment_indicator_array_l *  (p_realized - exposure_indicator_array)\n",
    "                dl2dmu = exposure_indicator_array * (mus_T -rewards_array)\n",
    "                gradient_vector_l = np.concatenate([dl1dtheta0]+[dl1dthetal_dict[l] for l in range(L)] +[dl2dmu], axis =1 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ## 2. COMPUTE  THE GRADIENT OF H FUNCTION\n",
    "                dHdtheta0 = p_T * (mus_T - Ey1.reshape(mus_T.shape[0],1)) - p_C * (mus_C - Ey0.reshape(mus_C.shape[0],1))\n",
    "                dHdtheta0 = dHdtheta0[:, 1:]\n",
    "\n",
    "\n",
    "\n",
    "                ## FIX: iterate over each l \n",
    "                dHdthetal_dict = {} \n",
    "                for l in range(L):\n",
    "\n",
    "                    p_T_thetal = counterfactual_pred_dict[l][:,:k]\n",
    "                    Eyl = np.sum(mus_T * p_T_thetal, axis = 1)\n",
    "                    dHdthetal_dict[l] = p_T_thetal * (mus_T - Eyl.reshape(mus_T.shape[0],1))\n",
    "                    ## 0 for the groups that are not the target treatment group \n",
    "                    if l != ith_treat:\n",
    "                        dHdthetal_dict[l] = 0 * (p_T_thetal * (mus_T - Eyl.reshape(mus_T.shape[0],1)))\n",
    "\n",
    "                #dHdthetal = p_T * (mus_T - Ey1.reshape(mus_T.shape[0],1))\n",
    "                dHdmu = p_T - p_C\n",
    "                #gradient_vector_H = np.concatenate([dHdtheta0,dHdthetal,dHdmu], axis =1 )\n",
    "\n",
    "                ## FIX: iterate over all l \n",
    "                gradient_vector_H = np.concatenate([dHdtheta0]+[dHdthetal_dict[l] for l in range(L)]+[dHdmu], axis =1 )\n",
    "                ## Gradient over all other treatments \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ## 3. FIND THE EXPECTATION OF HESSIAN MATRIX \n",
    "\n",
    "\n",
    "\n",
    "                Hessian_all = np.zeros((inputs_3d_test.shape[0],(L+2) * K - 1,  (L+2) * K - 1))\n",
    "\n",
    "                montecarlo_expected_probability = np.zeros(exposure_indicator_array.shape)\n",
    "\n",
    "                selected_indicator_dict  = {}\n",
    "                assignment_pd_dict = {} \n",
    "                dmu_dict = {} \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                for m in range(M):\n",
    "                    treat_dict_m = permute_treatment_dict(J)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                M = 500\n",
    "                for m in range(M):\n",
    "                    w_dict_m = {} \n",
    "                    treat_dict_m = permute_treatment_dict(J)\n",
    "                    W_matrix_m = []\n",
    "                    for i in range(np.array(query_matrix).shape[0]):\n",
    "                        ## Form the consideration set \n",
    "                        each_query=np.array(query_matrix)[i,:]\n",
    "                        W_matrix_m = np.append(W_matrix_m, [[treat_dict_m[ind] for ind in each_query]])\n",
    "\n",
    "                    W_matrix_m = W_matrix_m.reshape(np.array(query_matrix).shape)\n",
    "\n",
    "\n",
    "\n",
    "                    for l in range(L):\n",
    "                        w_dict_m[l] = tf.convert_to_tensor(W_matrix_m == groupNames[l + 1], dtype = float)\n",
    "\n",
    "\n",
    "                    inputs_3d_m = tf.stack([X_goodbads,X_utility]+  [w_dict_m[l] for l in range(L)] +[X_goodbads], axis = -1)\n",
    "                    inputs_3d_test_m = inputs_3d_m[f_start:f_end,:]\n",
    "                    model_pred_m = np.array(myModelMultiple.predict(inputs_3d_test_m))[:,:k]\n",
    "                    outer_product_pv1pv2 = np.array([np.outer(row_[1:], row_[1:]) for row_ in model_pred_m])\n",
    "                    outer_product_treatment_indicator = np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                    outer_product_pv1_one_minus_pv2 = np.array([np.outer(row_, 1-row_) for row_ in model_pred_m])\n",
    "                    p_treat = 1/(L+1) \n",
    "\n",
    "                    is_selected_indicator_test = np.array(exposure_matrix[f_start:f_end,:])\n",
    "                    selected_indicator_dict[m] = is_selected_indicator_test \n",
    "                    d2l2dtheta0 = - np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "\n",
    "                    ## FIX: Iterate over l \n",
    "                    d2l2dthetal_dict = {}\n",
    "                    for l in range(L):\n",
    "                        ## K by K \n",
    "\n",
    "                        w_m_l = np.array(w_dict_m[l][f_start:f_end,:])\n",
    "\n",
    "                        ## Off-diagonal terms \n",
    "                        # d2l2dtheta1 =  np.array([np.outer(row_, row_) for row_ in w_m_l]) * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                        d2l2dtheta1 = - p_treat * p_treat * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                        ## Modify diagonal terms\n",
    "                        for i in range(d2l2dtheta1.shape[0]):\n",
    "                            treat_indicator_i = w_m_l[i,:]\n",
    "                            probs_i = model_pred_m[i,:]\n",
    "                            # np.fill_diagonal(d2l2dtheta1[i],treat_indicator_i * probs_i * (1-probs_i))\n",
    "                            np.fill_diagonal(d2l2dtheta1[i], p_treat * probs_i * (1-probs_i))\n",
    "                        d2l2dthetal_dict[l] = d2l2dtheta1\n",
    "\n",
    "\n",
    "\n",
    "                    ## FIX: iterate over all l1, l2 \n",
    "                    d2ldthetal1dthetal2 = {} \n",
    "                    for l in range(L):\n",
    "                        w_m_l = np.array(w_dict_m[l][f_start:f_end,:])\n",
    "                        ## Off-diagonal terms \n",
    "                        #d2l2dtheta0dtheta1 = - np.multiply(w_m_l[:,np.newaxis], np.array([np.outer(row_, row_) for row_ in model_pred_m]))\n",
    "                        d2l2dtheta0dtheta1 = - p_treat * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                        for i in range(d2l2dtheta0dtheta1.shape[0]):\n",
    "                            treat_indicator_i = w_m_l[i,:]\n",
    "                            p_1minusp_i = model_pred_m[i,:] * (1 - model_pred_m[i,:])\n",
    "                            #np.fill_diagonal(d2l2dtheta0dtheta1[i], treat_indicator_i * p_1minusp_i)\n",
    "                            np.fill_diagonal(d2l2dtheta0dtheta1[i], p_treat * p_1minusp_i)\n",
    "\n",
    "                        ## NOTE: -1 to indicate the baseline theta \n",
    "                        d2ldthetal1dthetal2[(-1,l)] = d2l2dtheta0dtheta1[:,1:,:]\n",
    "                        d2ldthetal1dthetal2[(l,-1)] = np.transpose(d2l2dtheta0dtheta1[:,1:,:], (0,2,1))\n",
    "                        for l_prime in range(L):\n",
    "                            if l != l_prime: \n",
    "                                #w_m_l = np.array(w_dict_m[l][training_num:,:])\n",
    "                                #w_m_l_prime = np.array(w_dict_m[l_prime][training_num:,:])\n",
    "                                #indicator_outer = np.array([np.outer(w_m_l[i,:], w_m_l_prime[i,:]) for i in range(w_m_l.shape[0])])\n",
    "\n",
    "                                #d2l2dthetal1dthetal2 = -  indicator_outer * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                                d2l2dthetal1dthetal2 = -  p_treat * p_treat * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                                d2ldthetal1dthetal2[(l,l_prime)]  = d2l2dthetal1dthetal2\n",
    "                                d2ldthetal1dthetal2[(l_prime,l)]  = np.transpose(d2l2dthetal1dthetal2, (0,2,1))\n",
    "                            else:\n",
    "                                d2ldthetal1dthetal2[(l,l)] = d2l2dthetal_dict[l]\n",
    "\n",
    "\n",
    "                    d2l2dmu = np.zeros(d2l2dtheta1.shape)\n",
    "\n",
    "                    # treatment_indicator_array_m = \n",
    "                    for i in range(d2l2dmu.shape[0]):\n",
    "                        #p_1minusp_i = (1 - model_pred_m[i,:]) * (1 - model_pred_m[i,:])\n",
    "                        p_1minusp_i = model_pred_m[i,:] * (1 - model_pred_m[i,:])\n",
    "                        # treatment_i = treatment_indicator_array[i,:]\n",
    "                        # exposure_i = is_selected_indicator_test[i,:]\n",
    "                        np.fill_diagonal(d2l2dtheta0[i], p_1minusp_i)\n",
    "                        np.fill_diagonal(d2l2dmu[i], model_pred_m[i,:])\n",
    "\n",
    "\n",
    "\n",
    "                    d2l2dtheta0 = d2l2dtheta0[:,1:, 1:]\n",
    "                    # d2l2dtheta01_k_m_1_by_k = d2l2dtheta01[:, 1:,:]\n",
    "                    # d2l2dtheta10_k_by_k_m_1 = d2l2dtheta01[:, :,1:]\n",
    "                    Hessian_first_row = np.concatenate([d2l2dtheta0] + [d2ldthetal1dthetal2[(-1, l)] for l in range(L)] + [np.zeros((d2l2dtheta0.shape[0], K-1, K))], axis =2)\n",
    "\n",
    "                    ## 1 to L + 1 row \n",
    "                    Hessian_middle_dict = {}\n",
    "                    for l in range(L):\n",
    "                        row_l = np.concatenate([d2ldthetal1dthetal2[(l, -1)]] + [d2ldthetal1dthetal2[(l, l_prime)] for l_prime in range(L)] +[np.zeros((d2l2dtheta0.shape[0], K, K))], axis =2)\n",
    "\n",
    "                        Hessian_middle_dict[l] = row_l                                                                           \n",
    "\n",
    "\n",
    "                    Hessian_third_row = np.concatenate((np.zeros((d2l2dtheta0.shape[0], K, K  * (L + 1 ) - 1 )), d2l2dmu), axis =2)\n",
    "\n",
    "                    Hessian = np.concatenate([Hessian_first_row] + [Hessian_middle_dict[l] for l in range(L)] + [Hessian_third_row], axis = 1 )\n",
    "\n",
    "                    dmu_dict[m] = d2l2dmu\n",
    "\n",
    "                    Hessian_all = Hessian_all + Hessian\n",
    "\n",
    "                Hessian_final = Hessian_all / M\n",
    "                count_finite = 0\n",
    "                score_funcs = np.zeros(len(Hessian_final))\n",
    "                for i in range(len(Hessian_final)):\n",
    "                    if is_invertible(Hessian_final[i]):\n",
    "                        try:\n",
    "                            score_funcs[i] = gradient_vector_H[i]@np.linalg.inv(Hessian_final[i])@gradient_vector_l[i]\n",
    "                            count_finite += 1 \n",
    "                        except: \n",
    "                            print(\"Fail for inversion\")\n",
    "                outs_1 = res_tempt[score_funcs !=0,K]\n",
    "\n",
    "\n",
    "                ## END OF FOR LOOP FOR EACH ITERATION OVER CROSS FITTING\n",
    "                hfuncs_f, debias_term_f = Ey1 - Ey0,score_funcs[score_funcs!=0]\n",
    "                # debias_point_f,  debias_var_f, undebiased_point_f  = debias_estimator(outs_1, score_funcs[score_funcs!=0])\n",
    "                # debias_point_each_fold += [debias_point_f]  \n",
    "                # debias_var_each_fold += [debias_var_f]\n",
    "                # undebiased_point_each_fold += [undebiased_point_f]\n",
    "                hfuncs_each_fold[f] =hfuncs_f\n",
    "                debias_terms_each_fold[f] = debias_term_f\n",
    "\n",
    "            tau_hat_undebias = np.mean([ np.mean(hfuncs_each_fold[f])for f in range(n_folds)])\n",
    "            tau_hat_debias = np.mean([ np.mean(hfuncs_each_fold[f] - debias_terms_each_fold[f])  for f in range(n_folds)])\n",
    "            debias_point = tau_hat_debias\n",
    "            debias_var = np.mean([debias_estimator_new(hfuncs_each_fold[f] ,debias_terms_each_fold[f], tau_hat_debias)[1] for f in range(n_folds)])\n",
    "            undebias_var = np.mean([undebias_estimator_new(hfuncs_each_fold[f] ,tau_hat_undebias)[1] for f in range(n_folds)])\n",
    "            undebias_point = tau_hat_undebias\n",
    "            dim_point, dim_var = dim_est(T, C)\n",
    "            dim_B += [dim_point]\n",
    "            dim_var_B += [dim_var]\n",
    "            debias_B_true += [debias_point]\n",
    "            debias_var_B_true += [debias_var]\n",
    "            undebias_B_true += [undebias_point]\n",
    "            undebias_var_B_true += [undebias_var]\n",
    "\n",
    "        result_df = pd.DataFrame({\"debias_point\": debias_B_true, \"debias_var\":debias_var_B_true, \"dim\": dim_B, \n",
    "                                 \"dim_var\":dim_var_B, \"undebias_point\": undebias_B_true, \"undebias_var\": undebias_var_B_true, \"J\" : J,\"Q\": Q, \"K\":K })\n",
    "        result_df.to_csv(\"result2405new/new_heterogeneous_{}_synthetic_ab_j{}q{}k{}_100_{}.csv\".format(str(int(time.time())),str(J), str(Q), str(K), str(uplift_ratio).replace('.','')))\n",
    "        plt.figure() \n",
    "        sns.kdeplot(np.array(debias_B_true) /  np.sqrt(np.array(debias_var_B_true)/(int(Q))) , shade = True,color=tencent_blue,label = \"Ours(debiased)\",alpha=0.1)\n",
    "        sns.kdeplot(np.array(undebias_B_true) /  np.sqrt(np.array(undebias_var_B_true)/(int(Q))) , shade = True,color='red',label = \"Ours(undebiased)\",alpha=0.1)\n",
    "        sns.kdeplot(np.array(dim_B) / np.sqrt(np.array(dim_var_B)), shade = True,color=tencent_orange,label = \"DIM\",alpha=0.1)\n",
    "        plt.plot(x, y_standard_normal, color='black', label=\"Standard Normal\", ls='--')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.savefig(\"result2405new/new_heterogeneous_{}_synthetic_ab_j{}q{}k{}_density{}.png\".format(str(int(time.time())), str(J), str(Q), str(K), str(uplift_ratio).replace('.','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.jupyter/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  \n",
      "/opt/.jupyter/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/.jupyter/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2cf8713250>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure() \n",
    "sns.kdeplot((np.array(debias_B_true)-ground_truth) /  np.sqrt(np.array(debias_var_B_true)/(int(Q))) , shade = True,color=tencent_blue,label = \"Ours(debiased)\",alpha=0.1)\n",
    "sns.kdeplot((np.array(undebias_B_true) - ground_truth) /  np.sqrt(np.array(undebias_var_B_true)/(int(Q))) , shade = True,color='red',label = \"Ours(undebiased)\",alpha=0.1)\n",
    "sns.kdeplot((np.array(dim_B) - ground_truth)/ np.sqrt(np.array(dim_var_B)), shade = True,color=tencent_orange,label = \"DIM\",alpha=0.1)\n",
    "plt.plot(x, y_standard_normal, color='black', label=\"Standard Normal\", ls='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
