{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import Model \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import layers\n",
    "from scipy.special import kl_div\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_ranking as tfr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated - April Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "x = np.linspace(-4, 4, 100)\n",
    "tencent_blue = (0,0.3215686274509804,0.8509803921568627)\n",
    "tencent_orange = (0.9333333333333333, 0.49411764705882355, 0.2784313725490196)\n",
    "\n",
    "\n",
    "# Calculate y-values for the standard normal density curve\n",
    "y_standard_normal = (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_probability_exposure_examination(probs_matrix, exposure_matrix): \n",
    "    aggregate_probs = np.mean(probs_matrix, axis = 0)\n",
    "    exposure_probs = np.mean(exposure_matrix, axis = 0)\n",
    "    ## Euclidean distance \n",
    "    euc_dist = np.linalg.norm(aggregate_probs - exposure_probs)\n",
    "    ## NDCG LOSS \n",
    "    y_true = tf.ragged.constant(exposure_matrix)\n",
    "    y_pred = tf.ragged.constant(probs_matrix)\n",
    "    loss_NDCG = tfr.keras.losses.ApproxNDCGLoss(ragged=True)\n",
    "    NDCG_loss_result = loss_NDCG(y_true, y_pred).numpy()\n",
    "    return euc_dist, aggregate_probs, exposure_probs, NDCG_loss_result\n",
    "def mySoftMax(arr):\n",
    "    num = np.exp(arr)\n",
    "    denom = np.sum(num)\n",
    "    return num/denom\n",
    "\n",
    "\n",
    "def naive_est(res):\n",
    "    treat_res = [elm[0] for elm in res[0]]\n",
    "    control_res = [elm[1] for elm in res[0]]\n",
    "    return np.mean(treat_res) - np.mean(control_res)\n",
    "\n",
    "\n",
    "def dim_est(obs_T, obs_C):\n",
    "    n1,n0 = len(obs_T), len(obs_C)\n",
    "    return np.mean(obs_T) -np.mean(obs_C), np.sqrt(np.var(obs_T)/n1 + np.var(obs_C) / n0)\n",
    "\n",
    "\n",
    "def point_est(all_treat_array, all_control_array):\n",
    "    mus_T, mus_C  = all_treat_array[:, 11:21], all_control_array[:,11:21]\n",
    "    p_T, p_C  = all_treat_array[:, 21:], all_control_array[:,21:]\n",
    "    return np.mean(np.sum((mus_T * (p_T - p_C)), axis = 1 ))\n",
    "\n",
    "\n",
    "def naive_dim_estimate(vector_T, vector_C):\n",
    "    return np.mean(vector_T) - np.mean(vector_C), np.var(vector_T)/len(vector_T) + np.var(vector_C) / len(vector_C)\n",
    "\n",
    "def debias_estimator(Hfuncs, debias_terms):\n",
    "    score_functions = Hfuncs - debias_terms \n",
    "    undebiased_estimator = np.mean(Hfuncs)\n",
    "    debiased_estimator = np.mean(score_functions)\n",
    "    variance_estimator = np.mean((score_functions - debiased_estimator)**2) /len(score_functions)\n",
    "    return debiased_estimator, variance_estimator, undebiased_estimator \n",
    "\n",
    "def debias_estimator_new(Hfuncs, debias_terms,tau_hat):\n",
    "    psi_functions = Hfuncs - debias_terms \n",
    "    undebiased_estimator = np.mean(Hfuncs)\n",
    "    debiased_estimator = np.mean(psi_functions)\n",
    "    variance_estimator = np.mean((psi_functions - tau_hat)**2) /len(psi_functions)\n",
    "    return debiased_estimator, variance_estimator, undebiased_estimator \n",
    "\n",
    "\n",
    "def is_invertible(matrix):\n",
    "    return np.linalg.det(matrix) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## True Model \n",
    "\n",
    "class MyModel_True:\n",
    "    def __init__(self, k, num_treats,promo_ratio):\n",
    "\n",
    "        self.k = k\n",
    "        self.promo_ratio = promo_ratio\n",
    "        self.num_treats = num_treats\n",
    "\n",
    "    def predict(self,inputs):\n",
    "        Q_input = inputs.shape[0]\n",
    "        split_structure =  [1]+ [1] + [1] * self.num_treats + [1]\n",
    "        splitted_elements = tf.split(inputs, split_structure, axis=2)\n",
    "        X_utility =  np.squeeze(np.array(splitted_elements[1]), axis=2)\n",
    "        X_goodbads = np.squeeze(np.array(splitted_elements[0]), axis = 2)\n",
    "\n",
    "        W_matrix =  np.squeeze(np.array(splitted_elements[2]), axis =2 )\n",
    "\n",
    "        final_score_matrix = (1 + W_matrix * self.promo_ratio * X_goodbads) * X_utility\n",
    "\n",
    "        ## First element of each row \n",
    "        first_elm = X_utility[:,0]\n",
    "        minus_matrix = first_elm.reshape((len(first_elm),1))@np.ones((1,K))\n",
    "        final_score_matrix_normalized = final_score_matrix - minus_matrix\n",
    "        ## Correct exposure probability \n",
    "        X_logit = np.apply_along_axis(logistic_row, axis=1, arr=final_score_matrix_normalized)\n",
    "    \n",
    "        expose_indices = np.argmax(X_logit, axis = 1)\n",
    "        inddds = np.array(list(np.arange(K)) * Q_input).reshape(Q_input,K)\n",
    "        exposure_matrix = np.array([inddds[i,:] == expose_indices[i] for i in range(Q_input)])\n",
    "\n",
    "        ## Outcome model  \n",
    "        \n",
    "        ## First: a true outcome model of Exponential \n",
    "        outcome_potential = np.random.normal(size=(Q_input, K)) +  X_utility\n",
    "        pred_out = np.sum(exposure_matrix * outcome_potential, axis = 1 )\n",
    "        pred_out = pred_out.reshape(pred_out.shape[0], 1 )\n",
    "        return np.concatenate([X_logit, pred_out], axis = 1 )\n",
    "## True Model \n",
    "\n",
    "class MyModel_Random:\n",
    "    def __init__(self, k, num_treats,promo_ratio):\n",
    "\n",
    "        self.k = k\n",
    "        self.promo_ratio = promo_ratio\n",
    "        self.num_treats = num_treats\n",
    "\n",
    "    def predict(self,inputs):\n",
    "        output_shape = np.array(input_3d_test_treat.shape)[:2]\n",
    "        array = np.random.rand(output_shape[0],output_shape[1])\n",
    "        # Compute the sum of each row\n",
    "        row_sums = np.sum(array, axis=1)\n",
    "\n",
    "        # Reshape the row sums to make them compatible for broadcasting\n",
    "        row_sums = row_sums.reshape(-1, 1)\n",
    "\n",
    "        normalized_array = array / row_sums\n",
    "\n",
    "        return normalized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of videos \n",
    "J = 50 \n",
    "## Consideration set size \n",
    "K = 10 \n",
    "k=10\n",
    "## Generate some queries along with the recommendation model \n",
    "Q = 1000\n",
    "\n",
    "\n",
    "def permute_treatment_dict(J):\n",
    "    perm_dict = {}\n",
    "    for j in range(J):\n",
    "        perm_dict[j] = np.random.choice([True,False], 1)\n",
    "    return perm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## True Exposure Model and Data Generating Process \n",
    "def logistic_row(row):\n",
    "    return np.exp(row) / np.sum(np.exp(row))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# I. deterministic: \n",
    "# selected_indices = np.argmax(X_logit, axis = 1)\n",
    "# II. random choice for exposure \n",
    "\n",
    "def DGP(promo_rat, K,Q, J):\n",
    "    ## Generate a utility score for each viewer and video pair\n",
    "    utility_score_matrix = np.exp(np.random.normal(size=(Q,J)))\n",
    "    good_bad_dict = {} \n",
    "    treatment_dict = {} \n",
    "    utility_score = {} \n",
    "    for j in range(J):\n",
    "        good_bad_dict[j] = np.random.choice([True,False], 1)\n",
    "        treatment_dict[j] = np.random.choice([True,False], 1)\n",
    "        utility_score[j] = np.random.uniform()\n",
    "    X_goodbads = []\n",
    "    X_utility = []\n",
    "    W_matrix = []\n",
    "    query_matrix = []\n",
    "    promo_ratio = promo_rat\n",
    "    for each_query in range(Q):\n",
    "        ## Form the consideration set \n",
    "        selected_indices = np.random.choice(np.arange(J), K, replace= False)\n",
    "        query_matrix += [selected_indices]\n",
    "        X_goodbads = np.append(X_goodbads,[good_bad_dict[ind] for ind in selected_indices])\n",
    "        X_utility = np.append(X_utility, [utility_score_matrix[each_query, ind] for ind in selected_indices])\n",
    "        W_matrix = np.append(W_matrix, [treatment_dict[ind] for ind in selected_indices])\n",
    "    X_goodbads = X_goodbads.reshape(Q, K)\n",
    "    X_utility = X_utility.reshape(Q, K)\n",
    "    W_matrix = W_matrix.reshape(Q,K)\n",
    "    final_score_matrix = (1 + W_matrix * promo_ratio * X_goodbads) * X_utility\n",
    "\n",
    "    X_logit = np.apply_along_axis(logistic_row, axis=1, arr=final_score_matrix)\n",
    "    expose_indices = np.array([np.random.choice(np.arange(K), size = 1, p = X_logit[i,:]) for i in range(Q)])\n",
    "    inddds = np.array(list(np.arange(K)) * Q).reshape(Q,K)\n",
    "    exposure_matrix = np.array([inddds[i,:] == expose_indices[i] for i in range(Q)])\n",
    "\n",
    "    ## Outcome model  \n",
    "    ## First: a true outcome model of Exponential \n",
    "    outcome_potential = np.random.normal(size=(Q, K)) +  X_utility\n",
    "\n",
    "    return query_matrix,X_goodbads,X_utility,W_matrix, exposure_matrix, outcome_potential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_B, dim_var_B= [],[]\n",
    "debias_B_true, debias_var_B_true = [],[] \n",
    "undebias_B_true, debias_var_old_B_true = [],[]\n",
    "truth= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function for cross validation\n",
    "def generate_indices(n, K):\n",
    "    ## Split original sample of size n into K sets \n",
    "    indices = np.linspace(0, n, K+1, dtype=int)\n",
    "    return list(zip(indices[:-1], indices[1:]))\n",
    "\n",
    "\n",
    "def train_test_split(input_data, all_inds, kth_test):\n",
    "    \n",
    "    training_ind = [all_inds[i] for i in range(len(all_inds)) if i != kth_test]\n",
    "    test_start, test_end = all_inds[kth_test]\n",
    "    if not tf.is_tensor(input_data):\n",
    "        training_data = np.concatenate([input_data[elm[0]:elm[1]] for elm in training_ind])\n",
    "    else:\n",
    "        \n",
    "        training_data = tf.concat([input_data[elm[0]:elm[1]] for elm in training_ind], axis = 0)\n",
    "    testing_data = input_data[test_start:test_end]\n",
    "    return training_data, testing_data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_arr = np.array(query_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inds = generate_indices(test_arr.shape[0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d_tmp, test_d_tmp = train_test_split(test_arr, all_inds, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr_tf = tf.cast(test_arr, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(800, 5), dtype=float32, numpy=\n",
       " array([[31., 11., 46., 43., 17.],\n",
       "        [30., 18., 22., 27., 47.],\n",
       "        [ 4., 47., 39., 10., 16.],\n",
       "        ...,\n",
       "        [ 4., 46., 45., 10., 41.],\n",
       "        [ 4., 43.,  6., 45.,  3.],\n",
       "        [ 3.,  5., 27., 21., 39.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(200, 5), dtype=float32, numpy=\n",
       " array([[13., 31.,  4., 43., 22.],\n",
       "        [48., 36.,  4., 19., 38.],\n",
       "        [17.,  3., 49., 36., 29.],\n",
       "        [15.,  5., 26., 48., 43.],\n",
       "        [24.,  6., 45.,  9.,  7.],\n",
       "        [29., 36.,  9., 32., 11.],\n",
       "        [47.,  3., 42., 33., 40.],\n",
       "        [18., 23.,  5.,  9., 12.],\n",
       "        [34., 21., 35., 42., 17.],\n",
       "        [23.,  4., 37., 43., 48.],\n",
       "        [27., 42., 21., 22., 29.],\n",
       "        [11.,  5.,  6., 16., 28.],\n",
       "        [11., 14.,  2., 42., 21.],\n",
       "        [39., 27., 32., 46., 49.],\n",
       "        [38., 33., 25., 46., 34.],\n",
       "        [12., 31.,  8., 45., 22.],\n",
       "        [27., 37.,  8.,  2.,  5.],\n",
       "        [42., 32., 22., 43., 15.],\n",
       "        [40., 28., 36., 17.,  0.],\n",
       "        [41.,  6., 49., 29., 21.],\n",
       "        [39., 41., 36.,  7., 14.],\n",
       "        [33., 27., 41., 14., 40.],\n",
       "        [29., 28., 32., 17., 46.],\n",
       "        [44.,  3., 41., 35., 25.],\n",
       "        [42.,  8., 39., 45., 44.],\n",
       "        [30.,  7.,  9., 40., 18.],\n",
       "        [16., 17., 41., 38.,  3.],\n",
       "        [ 4., 42., 34., 19., 11.],\n",
       "        [ 0., 28., 10., 38., 31.],\n",
       "        [39., 11., 36.,  3., 35.],\n",
       "        [42., 46.,  6., 20.,  7.],\n",
       "        [17., 48., 43.,  6., 14.],\n",
       "        [22., 37., 19., 13.,  5.],\n",
       "        [33., 44., 47., 34., 45.],\n",
       "        [43., 27., 32., 24., 14.],\n",
       "        [40., 44., 10., 39.,  2.],\n",
       "        [13., 21., 48., 35.,  5.],\n",
       "        [41., 46., 47., 29., 21.],\n",
       "        [22., 20.,  6., 16.,  8.],\n",
       "        [ 2., 16., 28., 21., 45.],\n",
       "        [34., 47.,  0., 27., 40.],\n",
       "        [13., 26., 34., 44., 25.],\n",
       "        [ 5.,  7.,  8., 47.,  4.],\n",
       "        [27., 47., 26., 13.,  0.],\n",
       "        [17.,  3., 18., 49., 27.],\n",
       "        [ 7., 18., 17., 10., 36.],\n",
       "        [20., 37.,  0., 28., 31.],\n",
       "        [39., 15., 25., 49., 41.],\n",
       "        [ 2.,  0., 14., 47., 49.],\n",
       "        [36.,  5., 10., 43., 26.],\n",
       "        [26., 17., 15.,  4.,  7.],\n",
       "        [13., 32., 20., 37., 17.],\n",
       "        [18., 36., 22.,  6., 15.],\n",
       "        [ 1., 27., 45.,  0., 49.],\n",
       "        [ 6., 45., 44.,  8.,  3.],\n",
       "        [ 3., 38., 46., 22., 35.],\n",
       "        [16., 34., 14., 31., 36.],\n",
       "        [47., 34., 20., 12., 23.],\n",
       "        [12., 37.,  7., 40.,  2.],\n",
       "        [ 8., 17.,  2., 35., 15.],\n",
       "        [35., 47., 48., 23., 39.],\n",
       "        [44., 39., 10.,  3.,  9.],\n",
       "        [29., 10., 22.,  9., 34.],\n",
       "        [26., 48., 37., 33.,  3.],\n",
       "        [29., 18., 33., 38., 36.],\n",
       "        [10.,  4., 37., 25., 32.],\n",
       "        [25., 37.,  7.,  4., 49.],\n",
       "        [11., 48., 37., 17., 29.],\n",
       "        [35.,  6.,  2.,  9., 12.],\n",
       "        [42., 16., 15., 25., 33.],\n",
       "        [14.,  6., 30., 32., 10.],\n",
       "        [11.,  9., 21.,  4.,  3.],\n",
       "        [39., 28., 48., 19., 20.],\n",
       "        [19., 13., 16., 20.,  0.],\n",
       "        [36.,  4., 43., 44., 17.],\n",
       "        [21., 36., 16., 39., 13.],\n",
       "        [39., 20., 27., 11.,  8.],\n",
       "        [45.,  2., 31., 47., 18.],\n",
       "        [47., 48., 31., 37., 39.],\n",
       "        [19.,  8., 38.,  6., 46.],\n",
       "        [48., 49.,  0., 29., 10.],\n",
       "        [45., 30., 34., 26., 10.],\n",
       "        [ 5., 13.,  1.,  9.,  8.],\n",
       "        [ 3., 13., 38., 45., 24.],\n",
       "        [12., 41.,  1.,  4., 45.],\n",
       "        [36., 22., 28., 14., 45.],\n",
       "        [10.,  4., 41., 23., 35.],\n",
       "        [10.,  8., 24., 14., 36.],\n",
       "        [32., 21., 28., 46., 34.],\n",
       "        [11., 44.,  6., 16.,  3.],\n",
       "        [ 6.,  3., 22., 28., 17.],\n",
       "        [38., 39.,  2., 44., 10.],\n",
       "        [17.,  1.,  2., 40., 15.],\n",
       "        [ 0., 38., 18., 31., 30.],\n",
       "        [15., 16., 38., 24., 29.],\n",
       "        [21.,  2., 44., 29., 23.],\n",
       "        [10.,  7., 21., 37., 39.],\n",
       "        [39., 49.,  7.,  5., 31.],\n",
       "        [41., 26.,  1., 32., 25.],\n",
       "        [34., 24., 45., 14., 28.],\n",
       "        [28.,  1., 29., 13., 36.],\n",
       "        [ 2., 44., 11., 10., 34.],\n",
       "        [42.,  1., 12., 35., 33.],\n",
       "        [25., 42.,  9.,  5., 31.],\n",
       "        [14.,  0., 37., 18., 35.],\n",
       "        [44.,  7.,  0., 36.,  9.],\n",
       "        [19., 49., 11., 22., 10.],\n",
       "        [17., 41.,  4.,  6., 14.],\n",
       "        [36., 41.,  3., 45., 26.],\n",
       "        [30.,  7., 23., 38., 11.],\n",
       "        [19., 33., 41., 30.,  5.],\n",
       "        [41., 20., 11., 27., 10.],\n",
       "        [ 8., 41., 42., 17., 24.],\n",
       "        [ 7., 30., 32.,  0.,  5.],\n",
       "        [36.,  7., 15., 14., 24.],\n",
       "        [13., 40., 19.,  5., 26.],\n",
       "        [ 8., 22., 31., 34., 28.],\n",
       "        [39.,  0., 26., 22., 16.],\n",
       "        [41., 43., 20., 36., 30.],\n",
       "        [30., 43.,  2., 41., 13.],\n",
       "        [ 8., 23.,  7.,  4., 44.],\n",
       "        [34.,  4.,  6., 32.,  3.],\n",
       "        [ 0., 16., 25., 48., 40.],\n",
       "        [25., 15., 22.,  0., 27.],\n",
       "        [27., 12., 16., 31., 10.],\n",
       "        [39., 18., 49., 42., 43.],\n",
       "        [ 2., 34., 37., 42., 23.],\n",
       "        [23., 12., 20.,  8., 49.],\n",
       "        [35.,  2., 27.,  6., 16.],\n",
       "        [29., 39.,  7.,  1.,  2.],\n",
       "        [23., 17.,  5., 46., 12.],\n",
       "        [20.,  7., 12., 24., 44.],\n",
       "        [21.,  8., 25., 44., 29.],\n",
       "        [37., 35., 48., 31.,  1.],\n",
       "        [24., 31., 37., 26., 39.],\n",
       "        [39., 11.,  8., 17.,  7.],\n",
       "        [ 7.,  9.,  3., 26., 17.],\n",
       "        [ 3.,  0., 30.,  6., 47.],\n",
       "        [12., 49., 32., 26., 42.],\n",
       "        [41.,  7.,  5.,  6., 26.],\n",
       "        [46., 29., 39., 44.,  9.],\n",
       "        [36., 45., 21., 20.,  2.],\n",
       "        [42., 41., 47., 27., 38.],\n",
       "        [31., 17., 12.,  0., 47.],\n",
       "        [31., 47., 41., 22., 44.],\n",
       "        [41., 40., 24., 49., 30.],\n",
       "        [39., 38., 24., 11., 23.],\n",
       "        [42., 12.,  7., 45., 40.],\n",
       "        [29., 36.,  8., 38., 32.],\n",
       "        [ 2., 47., 33., 48., 21.],\n",
       "        [35., 36.,  7., 18., 34.],\n",
       "        [34.,  1., 42., 29., 11.],\n",
       "        [47., 40., 29.,  8., 38.],\n",
       "        [23., 38., 36.,  0., 42.],\n",
       "        [40.,  8.,  2.,  0.,  3.],\n",
       "        [33., 38., 25., 17., 19.],\n",
       "        [10., 32., 38., 14., 25.],\n",
       "        [49.,  6., 29., 43., 13.],\n",
       "        [48.,  4., 23., 14., 11.],\n",
       "        [27., 45.,  2.,  9., 37.],\n",
       "        [45., 14., 48., 33.,  2.],\n",
       "        [ 1., 22., 32., 12., 38.],\n",
       "        [42., 12., 37., 24., 46.],\n",
       "        [47., 41., 23.,  3., 17.],\n",
       "        [40., 35.,  6., 48.,  3.],\n",
       "        [25., 22.,  8.,  0., 10.],\n",
       "        [44., 43., 38.,  1.,  8.],\n",
       "        [18., 38., 15., 23., 30.],\n",
       "        [12., 24., 36., 29., 18.],\n",
       "        [43., 45., 29.,  1., 32.],\n",
       "        [22.,  1., 44., 27., 45.],\n",
       "        [ 1., 22., 38., 13.,  9.],\n",
       "        [ 0., 32., 42., 25., 44.],\n",
       "        [ 6., 45., 28.,  0., 29.],\n",
       "        [15.,  1., 46., 37., 14.],\n",
       "        [ 8., 43.,  4., 30., 14.],\n",
       "        [30., 25., 18., 19., 37.],\n",
       "        [22., 40., 14., 30., 32.],\n",
       "        [ 3., 19., 11., 22., 48.],\n",
       "        [34., 41., 25.,  3., 16.],\n",
       "        [35., 20., 29., 40.,  7.],\n",
       "        [43., 19., 31., 24., 34.],\n",
       "        [32., 13., 25., 14.,  2.],\n",
       "        [ 4., 31., 46., 32.,  9.],\n",
       "        [31.,  9., 27., 18., 25.],\n",
       "        [46., 11.,  3., 40., 44.],\n",
       "        [ 1., 37., 13.,  3., 49.],\n",
       "        [48., 39., 13., 47., 10.],\n",
       "        [10., 14.,  6.,  3., 12.],\n",
       "        [34., 48., 27.,  8., 31.],\n",
       "        [29.,  5.,  3.,  7., 38.],\n",
       "        [14., 49., 20., 40., 46.],\n",
       "        [18.,  4., 32., 35., 21.],\n",
       "        [26., 35., 43., 13., 31.],\n",
       "        [30., 49., 18.,  8., 29.],\n",
       "        [ 6., 21., 28., 32., 49.],\n",
       "        [24.,  0., 26., 20., 47.],\n",
       "        [ 4., 27., 44., 18., 16.],\n",
       "        [28., 37.,  0., 38., 34.],\n",
       "        [ 4., 38., 46., 11.,  2.]], dtype=float32)>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(test_arr_tf, all_inds, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
       "array([[30., 18., 22., 27., 47.],\n",
       "       [ 4., 47., 39., 10., 16.],\n",
       "       [17., 16., 31., 25., 36.],\n",
       "       [17., 16., 31., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([test_arr_tf[1:4],test_arr_tf[3:4]], axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(query_matrix).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start K = 5, Q = 1000, J = 50\n",
      "0\n",
      "7/7 [==============================] - 0s 535us/step\n",
      "7/7 [==============================] - 0s 735us/step\n",
      "7/7 [==============================] - 0s 840us/step\n",
      "7/7 [==============================] - 0s 678us/step\n",
      "7/7 [==============================] - 0s 750us/step\n"
     ]
    }
   ],
   "source": [
    "## Number of iterations of DGP\n",
    "B = 100\n",
    "## Number of videos \n",
    "JQ_sizes = [(50,1000), (100,1000), (200, 1000)]\n",
    "training_ratio = 0.4\n",
    "\n",
    "num_features = 2 \n",
    "\n",
    "## Consideration set size \n",
    "Ks = [5,10,20]\n",
    "\n",
    "JQ_sizes = [(50,1000)]\n",
    "Ks = [5]\n",
    "\n",
    "\n",
    "for (J, Q) in JQ_sizes:\n",
    "    for K in Ks:\n",
    "        print(\"Start K = {}, Q = {}, J = {}\".format(str(K), str(Q), str(J)))\n",
    "        dim_B, dim_var_B= [],[]\n",
    "        debias_B_true, debias_var_B_true = [],[] \n",
    "        undebias_B_true, debias_var_old_B_true = [],[]\n",
    "        truth= []\n",
    "\n",
    "\n",
    "        ## True Outcome Model test \n",
    "        L = 1\n",
    "        ith_treat = 0\n",
    "        M = 100\n",
    "        groupNames = [0,1]\n",
    "        uplift_ratio = 0\n",
    "        k = K\n",
    "        n_folds = 5\n",
    "        for b in range(B):\n",
    "            if b % 20 == 0:\n",
    "                print(b)\n",
    "            ## DGP and data pre-processing \n",
    "            query_matrix,X_goodbads,X_utility,W_matrix, exposure_matrix, outcome_potential = DGP(uplift_ratio, K,Q,J)\n",
    "\n",
    "            ## Fix in v2: add cross-fitting to the code \n",
    "            all_inds = generate_indices(np.array(query_matrix).shape[0], n_folds)\n",
    "            \n",
    "\n",
    "            ## Iterate over each fold for cross-validation. \n",
    "\n",
    "            hfuncs_each_fold,  debias_terms_each_fold = {},{}\n",
    "            for f in range(n_folds):\n",
    "                f_start, f_end = all_inds[f]\n",
    "                query_train, query_test = train_test_split(np.array(query_matrix), all_inds, f)\n",
    "                X_goodbads_train, X_goodbads_test =  train_test_split(X_goodbads, all_inds, f) \n",
    "                X_utility_train, X_utility_test =  train_test_split(X_utility, all_inds, f)  \n",
    "                W_matrix_train, W_matrix_test = train_test_split(W_matrix, all_inds, f) \n",
    "                observed_queries_treatment = np.sum(exposure_matrix * W_matrix, axis = 1 )\n",
    "                observed_outcome = np.sum(outcome_potential * exposure_matrix, axis = 1 )\n",
    "\n",
    "                T, C = observed_outcome[observed_queries_treatment == groupNames[ith_treat + 1 ]] , observed_outcome[observed_queries_treatment == 0]  \n",
    "                exposure_matrix_train,exposure_matrix_test =train_test_split(exposure_matrix, all_inds, f) \n",
    "                outcome_matrix = exposure_matrix * outcome_potential\n",
    "                outcome_matrix = np.sum(outcome_matrix, axis = 1 ).reshape(outcome_matrix.shape[0],1)\n",
    "\n",
    "                observed_outcome_train, observed_outcome_test = train_test_split(observed_outcome, all_inds, f) \n",
    "                outcome_matrix_train, outcome_matrix_test = train_test_split(outcome_matrix, all_inds, f) \n",
    "                outcome_potential_train, outcome_potential_test = train_test_split(outcome_potential, all_inds, f)  \n",
    "                inputs_3d_train = tf.stack([X_goodbads_train,X_utility_train, W_matrix_train, X_utility_train ], axis = -1)\n",
    "                inputs_3d_test = tf.stack([X_goodbads_test,X_utility_test, W_matrix_test, X_utility_test], axis = -1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                input_3d_test_treat = tf.stack([X_goodbads_test,X_utility_test, np.ones(W_matrix_test.shape), X_utility_test], axis = -1)\n",
    "                input_3d_test_control = tf.stack([X_goodbads_test,X_utility_test, np.zeros(W_matrix_test.shape), X_utility_test], axis = -1)\n",
    "                output_3d_train = tf.concat([tf.cast(exposure_matrix_train, dtype=float),outcome_matrix_train], axis = 1)\n",
    "                output_3d_test = tf.concat([tf.cast(exposure_matrix_test, dtype=float),outcome_matrix_test ], axis = 1)\n",
    "\n",
    "                exposure_indicator_array = exposure_matrix_test\n",
    "\n",
    "\n",
    "                ## Get treatment indicator matrix\n",
    "                w_dict = {}\n",
    "\n",
    "                for l in range(L):\n",
    "                    w_dict[l] = tf.convert_to_tensor(W_matrix == groupNames[l+1], dtype = float)\n",
    "\n",
    "                training_num = int(W_matrix.shape[0] * training_ratio)\n",
    "                testing_num = W_matrix.shape[0] - training_num\n",
    "\n",
    "\n",
    "                w_all_treat = tf.convert_to_tensor(np.array([[1] * k for _ in range(W_matrix.shape[0])],dtype='float32'))\n",
    "                w_all_control = tf.convert_to_tensor(np.array([[0] * k for _ in range(W_matrix.shape[0])],dtype='float32'))\n",
    "\n",
    "                inputs_all_treat_3d = tf.stack([X_goodbads,X_utility] + [w_all_treat if l == ith_treat else w_all_control for l in range(L)] +[ X_utility], axis = 2)\n",
    "                inputs_all_control_3d = tf.stack([X_goodbads,X_utility] + [w_all_control if l == ith_treat else w_all_control for l in range(L)] +[ X_utility ], axis = 2)\n",
    "                inputs_all_treat_3d = tf.cast(inputs_all_treat_3d, dtype = 'float32')\n",
    "                inputs_all_control_3d = tf.cast(inputs_all_control_3d, dtype = 'float32')\n",
    "\n",
    "                ## All other all_treated \n",
    "                inputs_all_treat_3d_dict = {} \n",
    "                for l in range(L):\n",
    "                    inputs_all_treat_3d_l = tf.stack([X_goodbads,X_utility] + [w_all_treat if l == v else w_all_control for v in range(L)] +[ X_utility ], axis = 2)\n",
    "                    #inputs_all_treat_3d_l = tf.stack([x_basebid, x_sort_score, x_bid,x_ecpm, x_cvr] + [w_all_treat if v == l else w_all_control for v in range(L)] + [x_cvr], axis = 2)\n",
    "                    inputs_all_treat_3d_dict[l] = tf.cast(inputs_all_treat_3d_l, dtype = 'float32')\n",
    "\n",
    "                exposure_indicator_outcome_train, exposure_indicator_outcome_test = outcome_matrix_train, outcome_matrix_test\n",
    "                inputs_all_treat_3d_test = input_3d_test_treat\n",
    "                inputs_all_control_3d_test = input_3d_test_control\n",
    "                is_selected_indicator_train,is_selected_indicator_test = exposure_matrix_train,exposure_matrix_test\n",
    "\n",
    "                treat_control_dict = {} \n",
    "                for l in range(L):\n",
    "\n",
    "                    \n",
    "                    inputs_3d_train_l,inputs_3d_test_l= train_test_split(inputs_all_treat_3d_dict[l], all_inds, f) \n",
    "\n",
    "                    treat_control_dict[l] = {'train':inputs_3d_train_l, 'test': inputs_3d_test_l}\n",
    "\n",
    "                myModelMultiple = MyModel_True(K, L, uplift_ratio)\n",
    "                myModelMultiple_random = MyModel_Random(K, L, uplift_ratio)\n",
    "                # myModelMultiple.compile(loss=custom_loss,optimizer=tf.keras.optimizers.legacy.Adam())\n",
    "                # myModelMultiple.fit(input_3d_train,output_3d_train , epochs=10, verbose=False)\n",
    "                exposure_indicator_array = is_selected_indicator_test\n",
    "                treatment_indicator_array = 1 * (np.array(w_dict[ith_treat])[f_start:f_end,:])\n",
    "\n",
    "                res_tempt = np.array(myModelMultiple.predict(inputs_all_treat_3d_test)) - np.array(myModelMultiple.predict(inputs_all_control_3d_test))\n",
    "\n",
    "\n",
    "                pred_H_new = np.array(myModelMultiple.predict(inputs_all_treat_3d_test)) - np.array(myModelMultiple.predict(inputs_all_control_3d_test))\n",
    "                model_pred_H = np.array(myModelMultiple.predict(inputs_3d_test))\n",
    "                model_pred_all_treat = myModelMultiple.predict(inputs_all_treat_3d_test)\n",
    "                model_pred_all_control = myModelMultiple.predict(inputs_all_control_3d_test)\n",
    "                all_treat_array, all_control_array = np.array(model_pred_all_treat), np.array(model_pred_all_control)\n",
    "\n",
    "                ## All other counterfactuals \n",
    "                counterfactual_pred_dict = {} \n",
    "                for l in range(L):\n",
    "                    model_pred_all_l = myModelMultiple.predict(treat_control_dict[l]['test'])\n",
    "                    counterfactual_pred_dict[l] = model_pred_all_l\n",
    "\n",
    "                ## Outcome - prediction model \n",
    "                indicator_bool = tf.cast(is_selected_indicator_train, dtype=tf.bool)\n",
    "                selected_elements = tf.boolean_mask(inputs_3d_train[:,:,:num_features], indicator_bool)\n",
    "\n",
    "                input_to_outcomemodel_train = tf.reshape(selected_elements, (inputs_3d_train.shape[0], num_features))\n",
    "                # Define your base model\n",
    "                base_model = tf.keras.Sequential()\n",
    "                base_model.add(layers.Dense(1, input_shape=(num_features,)))\n",
    "\n",
    "                # Compile the model\n",
    "                base_model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "                base_model.fit(input_to_outcomemodel_train,output_3d_train[:, K],epochs=50, verbose=False)\n",
    "                # Now define a new model for prediction\n",
    "                model_for_prediction = tf.keras.Sequential()\n",
    "                model_for_prediction.add(layers.TimeDistributed(base_model, input_shape=(K, num_features)))\n",
    "                predictions = model_for_prediction.predict(inputs_3d_test[:,:,:num_features])\n",
    "                # Remove the third dimension of size 1\n",
    "                numpy_array_pred = np.squeeze(predictions, axis=2)\n",
    "\n",
    "                mus_T, mus_C  = numpy_array_pred,numpy_array_pred\n",
    "                p_T, p_C  = all_treat_array[:, :k], all_control_array[:,:k]\n",
    "                rewards_array = observed_outcome_test\n",
    "                rewards_array = rewards_array.reshape(rewards_array.shape[0],1)\n",
    "                Ey1,Ey0 = np.sum(mus_T * p_T, axis = 1), np.sum(mus_C * p_C, axis = 1)\n",
    "                pv1,pv0 = np.sum(exposure_indicator_array * p_T, axis = 1), np.sum(exposure_indicator_array * p_C, axis = 1)\n",
    "\n",
    "                pv_given_uvw = p_T * treatment_indicator_array + p_C * (1 - treatment_indicator_array)\n",
    "\n",
    "\n",
    "                p_realized = model_pred_H[:,:K]\n",
    "\n",
    "\n",
    "\n",
    "                ## 1. COMPUTE THE GRADIENT OF LOSSS  \n",
    "                ## FIX: change to realized outcome \n",
    "                #dl1dtheta0 = pv_given_uvw - exposure_indicator_array\n",
    "                dl1dtheta0 = p_realized - exposure_indicator_array\n",
    "                dl1dtheta0 = dl1dtheta0[:, 1:] \n",
    "\n",
    "\n",
    "                ## FIX: iterate over all L \n",
    "                dl1dthetal_dict = {} \n",
    "                for l in range(L):\n",
    "                    treatment_indicator_array_l = w_dict[l][f_start:f_end, :]\n",
    "                    dl1dthetal_dict[l] = treatment_indicator_array_l *  (p_realized - exposure_indicator_array)\n",
    "                dl2dmu = exposure_indicator_array * (mus_T -rewards_array)\n",
    "                gradient_vector_l = np.concatenate([dl1dtheta0]+[dl1dthetal_dict[l] for l in range(L)] +[dl2dmu], axis =1 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ## 2. COMPUTE  THE GRADIENT OF H FUNCTION\n",
    "                dHdtheta0 = p_T * (mus_T - Ey1.reshape(mus_T.shape[0],1)) - p_C * (mus_C - Ey0.reshape(mus_C.shape[0],1))\n",
    "                dHdtheta0 = dHdtheta0[:, 1:]\n",
    "\n",
    "\n",
    "\n",
    "                ## FIX: iterate over each l \n",
    "                dHdthetal_dict = {} \n",
    "                for l in range(L):\n",
    "\n",
    "                    p_T_thetal = counterfactual_pred_dict[l][:,:k]\n",
    "                    Eyl = np.sum(mus_T * p_T_thetal, axis = 1)\n",
    "                    dHdthetal_dict[l] = p_T_thetal * (mus_T - Eyl.reshape(mus_T.shape[0],1))\n",
    "                    ## 0 for the groups that are not the target treatment group \n",
    "                    if l != ith_treat:\n",
    "                        dHdthetal_dict[l] = 0 * (p_T_thetal * (mus_T - Eyl.reshape(mus_T.shape[0],1)))\n",
    "\n",
    "                #dHdthetal = p_T * (mus_T - Ey1.reshape(mus_T.shape[0],1))\n",
    "                dHdmu = p_T - p_C\n",
    "                #gradient_vector_H = np.concatenate([dHdtheta0,dHdthetal,dHdmu], axis =1 )\n",
    "\n",
    "                ## FIX: iterate over all l \n",
    "                gradient_vector_H = np.concatenate([dHdtheta0]+[dHdthetal_dict[l] for l in range(L)]+[dHdmu], axis =1 )\n",
    "                ## Gradient over all other treatments \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ## 3. FIND THE EXPECTATION OF HESSIAN MATRIX \n",
    "\n",
    "\n",
    "\n",
    "                Hessian_all = np.zeros((inputs_3d_test.shape[0],(L+2) * K - 1,  (L+2) * K - 1))\n",
    "\n",
    "                montecarlo_expected_probability = np.zeros(exposure_indicator_array.shape)\n",
    "\n",
    "                selected_indicator_dict  = {}\n",
    "                assignment_pd_dict = {} \n",
    "                dmu_dict = {} \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                for m in range(M):\n",
    "                    treat_dict_m = permute_treatment_dict(J)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                M = 500\n",
    "                for m in range(M):\n",
    "                    w_dict_m = {} \n",
    "                    treat_dict_m = permute_treatment_dict(J)\n",
    "                    W_matrix_m = []\n",
    "                    for i in range(np.array(query_matrix).shape[0]):\n",
    "                        ## Form the consideration set \n",
    "                        each_query=np.array(query_matrix)[i,:]\n",
    "                        W_matrix_m = np.append(W_matrix_m, [[treat_dict_m[ind] for ind in each_query]])\n",
    "\n",
    "                    W_matrix_m = W_matrix_m.reshape(np.array(query_matrix).shape)\n",
    "\n",
    "\n",
    "\n",
    "                    for l in range(L):\n",
    "                        w_dict_m[l] = tf.convert_to_tensor(W_matrix_m == groupNames[l + 1], dtype = float)\n",
    "\n",
    "\n",
    "                    inputs_3d_m = tf.stack([X_goodbads,X_utility]+  [w_dict_m[l] for l in range(L)] +[X_goodbads], axis = -1)\n",
    "                    inputs_3d_test_m = inputs_3d_m[f_start:f_end,:]\n",
    "                    model_pred_m = np.array(myModelMultiple.predict(inputs_3d_test_m))[:,:k]\n",
    "                    outer_product_pv1pv2 = np.array([np.outer(row_[1:], row_[1:]) for row_ in model_pred_m])\n",
    "                    outer_product_treatment_indicator = np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                    outer_product_pv1_one_minus_pv2 = np.array([np.outer(row_, 1-row_) for row_ in model_pred_m])\n",
    "                    p_treat = 1/(L+1) \n",
    "\n",
    "                    is_selected_indicator_test = np.array(exposure_matrix[f_start:f_end,:])\n",
    "                    selected_indicator_dict[m] = is_selected_indicator_test \n",
    "                    d2l2dtheta0 = - np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "\n",
    "                    ## FIX: Iterate over l \n",
    "                    d2l2dthetal_dict = {}\n",
    "                    for l in range(L):\n",
    "                        ## K by K \n",
    "\n",
    "                        w_m_l = np.array(w_dict_m[l][f_start:f_end,:])\n",
    "\n",
    "                        ## Off-diagonal terms \n",
    "                        # d2l2dtheta1 =  np.array([np.outer(row_, row_) for row_ in w_m_l]) * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                        d2l2dtheta1 = - p_treat * p_treat * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                        ## Modify diagonal terms\n",
    "                        for i in range(d2l2dtheta1.shape[0]):\n",
    "                            treat_indicator_i = w_m_l[i,:]\n",
    "                            probs_i = model_pred_m[i,:]\n",
    "                            # np.fill_diagonal(d2l2dtheta1[i],treat_indicator_i * probs_i * (1-probs_i))\n",
    "                            np.fill_diagonal(d2l2dtheta1[i], p_treat * probs_i * (1-probs_i))\n",
    "                        d2l2dthetal_dict[l] = d2l2dtheta1\n",
    "\n",
    "\n",
    "\n",
    "                    ## FIX: iterate over all l1, l2 \n",
    "                    d2ldthetal1dthetal2 = {} \n",
    "                    for l in range(L):\n",
    "                        w_m_l = np.array(w_dict_m[l][f_start:f_end,:])\n",
    "                        ## Off-diagonal terms \n",
    "                        #d2l2dtheta0dtheta1 = - np.multiply(w_m_l[:,np.newaxis], np.array([np.outer(row_, row_) for row_ in model_pred_m]))\n",
    "                        d2l2dtheta0dtheta1 = - p_treat * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                        for i in range(d2l2dtheta0dtheta1.shape[0]):\n",
    "                            treat_indicator_i = w_m_l[i,:]\n",
    "                            p_1minusp_i = model_pred_m[i,:] * (1 - model_pred_m[i,:])\n",
    "                            #np.fill_diagonal(d2l2dtheta0dtheta1[i], treat_indicator_i * p_1minusp_i)\n",
    "                            np.fill_diagonal(d2l2dtheta0dtheta1[i], p_treat * p_1minusp_i)\n",
    "\n",
    "                        ## NOTE: -1 to indicate the baseline theta \n",
    "                        d2ldthetal1dthetal2[(-1,l)] = d2l2dtheta0dtheta1[:,1:,:]\n",
    "                        d2ldthetal1dthetal2[(l,-1)] = np.transpose(d2l2dtheta0dtheta1[:,1:,:], (0,2,1))\n",
    "                        for l_prime in range(L):\n",
    "                            if l != l_prime: \n",
    "                                #w_m_l = np.array(w_dict_m[l][training_num:,:])\n",
    "                                #w_m_l_prime = np.array(w_dict_m[l_prime][training_num:,:])\n",
    "                                #indicator_outer = np.array([np.outer(w_m_l[i,:], w_m_l_prime[i,:]) for i in range(w_m_l.shape[0])])\n",
    "\n",
    "                                #d2l2dthetal1dthetal2 = -  indicator_outer * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                                d2l2dthetal1dthetal2 = -  p_treat * p_treat * np.array([np.outer(row_, row_) for row_ in model_pred_m])\n",
    "                                d2ldthetal1dthetal2[(l,l_prime)]  = d2l2dthetal1dthetal2\n",
    "                                d2ldthetal1dthetal2[(l_prime,l)]  = np.transpose(d2l2dthetal1dthetal2, (0,2,1))\n",
    "                            else:\n",
    "                                d2ldthetal1dthetal2[(l,l)] = d2l2dthetal_dict[l]\n",
    "\n",
    "\n",
    "                    d2l2dmu = np.zeros(d2l2dtheta1.shape)\n",
    "\n",
    "                    # treatment_indicator_array_m = \n",
    "                    for i in range(d2l2dmu.shape[0]):\n",
    "                        #p_1minusp_i = (1 - model_pred_m[i,:]) * (1 - model_pred_m[i,:])\n",
    "                        p_1minusp_i = model_pred_m[i,:] * (1 - model_pred_m[i,:])\n",
    "                        # treatment_i = treatment_indicator_array[i,:]\n",
    "                        # exposure_i = is_selected_indicator_test[i,:]\n",
    "                        np.fill_diagonal(d2l2dtheta0[i], p_1minusp_i)\n",
    "                        np.fill_diagonal(d2l2dmu[i], model_pred_m[i,:])\n",
    "\n",
    "\n",
    "\n",
    "                    d2l2dtheta0 = d2l2dtheta0[:,1:, 1:]\n",
    "                    # d2l2dtheta01_k_m_1_by_k = d2l2dtheta01[:, 1:,:]\n",
    "                    # d2l2dtheta10_k_by_k_m_1 = d2l2dtheta01[:, :,1:]\n",
    "                    Hessian_first_row = np.concatenate([d2l2dtheta0] + [d2ldthetal1dthetal2[(-1, l)] for l in range(L)] + [np.zeros((d2l2dtheta0.shape[0], K-1, K))], axis =2)\n",
    "\n",
    "                    ## 1 to L + 1 row \n",
    "                    Hessian_middle_dict = {}\n",
    "                    for l in range(L):\n",
    "                        row_l = np.concatenate([d2ldthetal1dthetal2[(l, -1)]] + [d2ldthetal1dthetal2[(l, l_prime)] for l_prime in range(L)] +[np.zeros((d2l2dtheta0.shape[0], K, K))], axis =2)\n",
    "\n",
    "                        Hessian_middle_dict[l] = row_l                                                                           \n",
    "\n",
    "\n",
    "                    Hessian_third_row = np.concatenate((np.zeros((d2l2dtheta0.shape[0], K, K  * (L + 1 ) - 1 )), d2l2dmu), axis =2)\n",
    "\n",
    "                    Hessian = np.concatenate([Hessian_first_row] + [Hessian_middle_dict[l] for l in range(L)] + [Hessian_third_row], axis = 1 )\n",
    "\n",
    "                    dmu_dict[m] = d2l2dmu\n",
    "\n",
    "                    Hessian_all = Hessian_all + Hessian\n",
    "\n",
    "                Hessian_final = Hessian_all / M\n",
    "                count_finite = 0\n",
    "                score_funcs = np.zeros(len(Hessian_final))\n",
    "                for i in range(len(Hessian_final)):\n",
    "                    if is_invertible(Hessian_final[i]):\n",
    "                        score_funcs[i] = gradient_vector_H[i]@np.linalg.inv(Hessian_final[i])@gradient_vector_l[i]\n",
    "                        count_finite += 1 \n",
    "                outs_1 = res_tempt[score_funcs !=0,K]\n",
    "\n",
    "\n",
    "                ## END OF FOR LOOP FOR EACH ITERATION OVER CROSS FITTING\n",
    "                hfuncs_f, debias_term_f = outs_1,score_funcs[score_funcs!=0]\n",
    "                # debias_point_f,  debias_var_f, undebiased_point_f  = debias_estimator(outs_1, score_funcs[score_funcs!=0])\n",
    "                # debias_point_each_fold += [debias_point_f]  \n",
    "                # debias_var_each_fold += [debias_var_f]\n",
    "                # undebiased_point_each_fold += [undebiased_point_f]\n",
    "                hfuncs_each_fold[f] =hfuncs_f\n",
    "                debias_terms_each_fold[f] = debias_term_f\n",
    "\n",
    "            tau_hat_undebias = np.mean([ np.mean(hfuncs_each_fold[f])for f in range(n_folds)])\n",
    "            tau_hat_debias = np.mean([ np.mean(hfuncs_each_fold[f] - debias_terms_each_fold[f])  for f in range(n_folds)])\n",
    "            debias_point = tau_hat_debias\n",
    "            debias_var = np.mean([debias_estimator_new(hfuncs_each_fold[f] ,debias_terms_each_fold[f], tau_hat_debias) for f in range(n_folds)])\n",
    "            undebais_point = tau_hat_undebias\n",
    "            dim_point, dim_var = dim_est(T, C)\n",
    "            dim_B += [dim_point]\n",
    "            dim_var_B += [dim_var]\n",
    "            debias_B_true += [debias_point]\n",
    "            debias_var_B_true += [debias_var]\n",
    "            undebias_B_true += [undebiased_point]\n",
    "\n",
    "        result_df = pd.DataFrame({\"debias_point\": debias_B_true, \"debias_var\":debias_var_B_true, \"dim\": dim_B, \n",
    "                                 \"dim_var\":dim_var_B, \"undebias_point\": undebias_B_true, \"J\" : J,\"Q\": Q, \"K\":K })\n",
    "        result_df.to_csv(\"result2404/synthetic_aa_j{}q{}k{}_100.csv\".format(str(J), str(Q), str(K)))\n",
    "        plt.figure() \n",
    "        sns.kdeplot(np.array(debias_B_true) / np.sqrt(np.array(debias_var_B_true)) , shade = True,color=tencent_blue,label = \"Ours\",alpha=0.1)\n",
    "        sns.kdeplot(np.array(dim_B) / np.sqrt(np.array(dim_var_B)), shade = True,color=tencent_orange,label = \"DIM\",alpha=0.1)\n",
    "        plt.plot(x, y_standard_normal, color='black', label=\"Standard Normal\", ls='--')\n",
    "        plt.legend()\n",
    "        plt.savefig(\"result2404/synthetic_aa_j{}q{}k{}_density.png\".format(str(J), str(Q), str(K)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "expos_mat = exposure_matrix_test.astype(float)\n",
    "probs_mat = model_pred_H[:, :K]\n",
    "def bootstrap_evaluation(probs_mat, expos_mat, B = 100):\n",
    "    nrows = probs_mat.shape[0]\n",
    "    kl_div_list, NDCG_list = [], []\n",
    "    for b in range(B):\n",
    "        indices = np.random.choice(nrows, size=nrows, replace=True)\n",
    "        probs_mat_b = probs_mat[indices,:]\n",
    "        expos_mat_b = expos_mat[indices,:]\n",
    "        \n",
    "        _, agg_probs_b, agg_expos_b, NDCG_b = aggregate_probability_exposure_examination(probs_mat_b, expos_mat_b)\n",
    "        kl_divergence_b = kl_div(agg_probs_b,agg_expos_b).sum()\n",
    "\n",
    "        kl_div_list += [kl_divergence_b]\n",
    "        NDCG_list += [NDCG_b]\n",
    "    return kl_div_list, NDCG_list \n",
    "kl_, ndcg_ = bootstrap_evaluation(probs_mat.astype(np.float32), expos_mat.astype(np.float32))\n",
    "\n",
    "# aggregate_probability_exposure_examination(probs_mat.astype(np.float32), expos_mat.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Density'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(ndcg_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
